{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOZyGhYUhHtL"
   },
   "source": [
    "# Семинар 3: Представления слов: продолжение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter notebook --notebook-dir=\"D:/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T17:19:46.779934Z",
     "start_time": "2020-04-11T17:19:46.774947Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SBl0RozNEUcy",
    "outputId": "07617cc6-bda4-45df-cdbd-4504081bddfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "gensim\n",
    "pandas\n",
    "razdel\n",
    "sklearn\n",
    "allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T17:20:44.629865Z",
     "start_time": "2020-04-11T17:20:34.526099Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4U333X2sEruh",
    "outputId": "f7c1586e-31e6-4d9e-c9ec-48cf747c2929"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFpkTIeAjIIU"
   },
   "source": [
    "# Torch\n",
    "\n",
    "Один из самых известных и удобный фреймворков для обучения нейронных сетей. Не требует компиляции моделей, выполняет всё на лету.\n",
    "Основа - система автоматического дифференциирования Autograd. По сути Torch = numpy + Autograd + набор готовых модулей нейронных сетей\n",
    "\n",
    "\n",
    "*Фрагменты этой части взяты из https://github.com/DanAnastasyev/DeepNLP-Course*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5n0uvHxk_1v"
   },
   "source": [
    "### Графы вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-q8ulYQtlDTd"
   },
   "source": [
    "Графы вычислений - это такой удобный способ быстро считать градиенты сложных функций.\n",
    "\n",
    "Например, функция\n",
    "\n",
    "$$f = (x + y) \\cdot z$$\n",
    "\n",
    "представится графом\n",
    "\n",
    "![graph](https://image.ibb.co/mWM0Lx/1_6o_Utr7_ENFHOK7_J4l_XJtw1g.png)  \n",
    "*From [Backpropagation, Intuitions - CS231n](http://cs231n.github.io/optimization-2/)*\n",
    "\n",
    "Зададим значения $x, y, z$ (зеленым на картинке). Как посчитать $\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}$? (*Вспоминаем, что такое backpropagation*)\n",
    "\n",
    "В PyTorch такие вычисления делаются очень просто.\n",
    "\n",
    "Сначала определяется функция - просто последовательность операций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLZexrSSjQDj"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(-2., requires_grad=True)\n",
    "y = torch.tensor(5., requires_grad=True)\n",
    "z = torch.tensor(-4., requires_grad=True)\n",
    "\n",
    "q = x + y\n",
    "f = q * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCyKwBmHmImZ"
   },
   "source": [
    "А затем говорим ей: \"Посчитай градиенты, пожалуйста\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BucQUiS3mH-A",
    "outputId": "6af24a16-219c-48c5-9bd4-f9f598dcd4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dz = tensor(3.)\n",
      "df/dx = tensor(-4.)\n",
      "df/dy = tensor(-4.)\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "\n",
    "print('df/dz =', z.grad)\n",
    "print('df/dx =', x.grad)\n",
    "print('df/dy =', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIf_SeQ0mmsu"
   },
   "source": [
    "Подробнее о том, как работает autograd, можно почитать здесь: [Autograd mechanics](https://pytorch.org/docs/stable/notes/autograd.html).\n",
    "\n",
    "В целом, любой тензор в pytorch - аналог многомерных матриц в numpy.\n",
    "\n",
    "Он содержит данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XHypZY5gm1J8",
    "outputId": "9d23ef4b-e6cc-43ed-ab3a-43b729052787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CH21cqVgm33Y"
   },
   "source": [
    "Накопленный градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z2afyjI2m2ES",
    "outputId": "f4817799-1d0d-4825-abf6-b20178e6628d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFDjO_cHm9Ex"
   },
   "source": [
    "Функцию, как градиент считать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BepBXV-FnAhv",
    "outputId": "223acf38-03f0-4f83-a3a6-6f7b6beaed54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f8176f8eb70>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlLnJk6NnD5Q"
   },
   "source": [
    "И всякую дополнительную метаинформацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NpMMIvmNnGYa",
    "outputId": "341f9b79-9d3f-413a-e438-22a193aa8985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([]), device(type='cpu'), torch.strided)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(), x.shape, x.device, x.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSa-1SN-jLLb"
   },
   "source": [
    "# Свой Word2Vec\n",
    "\n",
    "А теперь обещанный самописный Word2Vec. Используем для его реализации Torch, хотя конкретно здесь можно было бы и обычным numpy обойтись (но было бы чуть больше сложностей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAuVSYDihXKV"
   },
   "source": [
    "### Подготовка\n",
    "\n",
    "Заново скачиваем всё с предудыщего семинара..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "yWuio1OBEuef",
    "outputId": "78ac3235-c7fa-461e-938c-fd7c627cb92d"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
    "!gzip -d lenta-ru-news.csv.gz\n",
    "!head -n 2 lenta-ru-news.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:00:43.670015Z",
     "start_time": "2020-04-12T21:58:57.328184Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xLuLCuuNExQB",
    "outputId": "857e9e97-c8bd-4b15-eb7a-57320705de56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['возобновление', 'нормального', 'сотрудничества', 'между', 'россией', 'и', 'нато', 'невозможно', 'пока', 'москва', 'не', 'будет', 'соблюдать', 'нормы', 'международного', 'права']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from razdel import tokenize, sentenize\n",
    "from string import punctuation\n",
    "\n",
    "def get_date(url):\n",
    "    dates = re.findall(r\"\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d\", url)\n",
    "    return next(iter(dates), None) \n",
    "\n",
    "# None на случай, если значения нет\n",
    "dataset = pd.read_csv(\"lenta-ru-news.csv\", sep=',', quotechar='\\\"', escapechar='\\\\', encoding='utf-8', header=0)\n",
    "dataset[\"date\"] = dataset[\"url\"].apply(lambda x: dt.datetime.strptime(get_date(x), \"%Y/%m/%d\"))\n",
    "dataset = dataset[dataset[\"date\"] > \"2017-01-01\"]\n",
    "dataset[\"text\"] = dataset[\"text\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "dataset[\"title\"] = dataset[\"title\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "train_dataset = dataset[dataset[\"date\"] < \"2018-04-01\"]\n",
    "test_dataset = dataset[dataset[\"date\"] > \"2018-04-01\"]\n",
    "\n",
    "texts = []\n",
    "# для каждого абзаца\n",
    "for text in train_dataset[\"text\"]:\n",
    "    \n",
    "# для каждого предложения\n",
    "    for sentence in sentenize(text):\n",
    "        # удаление пунктуации и токенизация\n",
    "        texts.append([token.text.lower() for token in tokenize(sentence.text) if token.text not in punctuation])\n",
    "    \n",
    "for title in train_dataset[\"title\"]:\n",
    "    texts.append([token.text.lower() for token in tokenize(title) if token.text not in punctuation])\n",
    "\n",
    "assert len(texts) == 827217\n",
    "assert len(texts[0]) > 0\n",
    "assert texts[0][0].islower()\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCLOK55Th1ZN"
   },
   "source": [
    "Напоминание...\n",
    "\n",
    "![embeddings training](https://miro.medium.com/max/1400/0*o2FCVrLKtdcxPQqc.png)\n",
    "*From [An implementation guide to Word2Vec using NumPy and Google Sheets\n",
    "](https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281)*\n",
    "\n",
    "Будем сами сторить skip-gram модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "No6CwYN9iNxf"
   },
   "source": [
    "## Предобработка и батчинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCdye7XdhdmH"
   },
   "source": [
    "До этого за нас gensim неявно строил словарь. Теперь придётся самим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание своего словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:00:45.975846Z",
     "start_time": "2020-04-12T22:00:43.670984Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "VXw1zgBnFzux",
    "outputId": "a21b48a6-187c-4b79-d46d-0e789ec5b7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112084\n",
      "['в', 'и', 'на', '«', '»', 'что', 'с', 'по', '—', 'не', 'из', 'этом', 'об', 'о', 'он', 'за', 'года', 'россии', 'к', 'его', 'для', 'как', 'также', 'от', 'а', 'это', 'сообщает', 'до', 'году', 'после', 'сша', 'у', 'во', 'время', 'был', 'при', 'заявил', 'со', 'словам', 'рублей', 'будет', 'ее', 'она', 'но', 'ранее', 'их', 'они', 'было', 'тысяч', 'более', 'того', 'том', 'мы', 'были', 'я', 'которые', 'все', 'который', 'человек', 'под', '2016', 'из-за', 'лет', '2017', 'украины', 'марта', 'процентов', 'чтобы', 'долларов', 'глава', 'президент', 'этого', 'отметил', 'же', 'сказал', 'так', 'января', 'или', 'страны', 'ру', 'то', 'еще', 'области', 'данным', 'была', 'президента', 'около', 'сообщил', 'февраля', 'однако', 'компании', 'может', 'уже', 'один', 'рассказал', 'только', 'процента', '1', '10', 'июня']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\n",
    "            \"<unk>\": 0\n",
    "        }\n",
    "        self.index2word = [\"<unk>\"]\n",
    "\n",
    "    def build(self, texts, min_count=5):\n",
    "        # Если нужно сделать двойной цикл, то порядок такой\n",
    "        words_counter = Counter(token for tokens in texts for token in tokens)\n",
    "        for word, count in words_counter.most_common():\n",
    "            if count >= min_count:\n",
    "                self.word2index[word] = len(self.word2index)\n",
    "        self.index2word = [word for word, _ in sorted(self.word2index.items(), key=lambda x: x[1])]\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.index2word)\n",
    "    \n",
    "    def top(self, n=100):\n",
    "        return self.index2word[1:n+1]\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        return self.word2index.get(word, 0)\n",
    "    \n",
    "    def get_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "vocabulary = Vocabulary()\n",
    "vocabulary.build(texts)\n",
    "assert vocabulary.word2index[vocabulary.index2word[10]] == 10\n",
    "print(vocabulary.size)\n",
    "print(vocabulary.top(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iVo213FiJK3"
   },
   "source": [
    "Собираем все центральные слова и их контексты, преобразуем в словарные индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:01:15.017626Z",
     "start_time": "2020-04-12T22:00:45.976805Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PIZSh1dGD4E2",
    "outputId": "f552617b-29e6-499c-a68d-7e2d329b4b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1568, [17232, 26343, 135, 371]), (135, [26343, 1568, 371, 2]), (371, [1568, 135, 2, 695]), (2, [135, 371, 695, 2140]), (695, [371, 2, 2140, 216])]\n",
      "сотрудничества ['возобновление', 'нормального', 'между', 'россией']\n"
     ]
    }
   ],
   "source": [
    "def build_contexts(tokenized_texts, vocabulary, window_size):\n",
    "    contexts = []\n",
    "    for tokens in tokenized_texts:\n",
    "        for i in range(len(tokens)):\n",
    "            central_word = vocabulary.get_index(tokens[i])\n",
    "            context = [vocabulary.get_index(tokens[i + delta]) for delta in range(-window_size, window_size + 1) \n",
    "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
    "            if len(context) != 2 * window_size:\n",
    "                continue\n",
    "\n",
    "            contexts.append((central_word, context))\n",
    "            \n",
    "    return contexts\n",
    "\n",
    "contexts = build_contexts(texts, vocabulary, window_size=2)\n",
    "print(contexts[:5])\n",
    "print(vocabulary.get_word(contexts[0][0]), [vocabulary.get_word(index) for index in contexts[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T21:56:35.649116Z",
     "start_time": "2020-04-12T21:56:35.641133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1568, [17232, 26343, 135, 371]),\n",
       " (135, [26343, 1568, 371, 2]),\n",
       " (371, [1568, 135, 2, 695]),\n",
       " (2, [135, 371, 695, 2140])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-L2oOckSnoC-"
   },
   "source": [
    "## Модель и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:11:57.556403Z",
     "start_time": "2020-04-12T18:11:57.311304Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings.forward(inputs)\n",
    "        output = self.out_layer.forward(projections) #F.log_softmax(, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:12:06.094722Z",
     "start_time": "2020-04-12T18:11:59.687346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([    24,    400,  83012,     10,      1,   1731,   2387,    311,     23,\n",
      "         11799,    526,    722,  24291,     19,   6622,  20093,    105,  30090,\n",
      "           851,      7,     16,   2968,  17499,      5,      2,   6122,  16837,\n",
      "           469,  10450,      4,      5,      1,  86508,    935,   7991,      1,\n",
      "             3,  10214,      1,    417,   3345,     24,     28, 100396,      2,\n",
      "           424,     99,     49,  38251,   6429,    414,     14,    771,    189,\n",
      "          3531,      1,  79429,    999,      4,   4785,      5,      9,      1,\n",
      "           267], device='cuda:0'), tensor([25149, 25149, 25149, 25149,     1,     1,     1,     1,  3629,  3629,\n",
      "         3629,  3629,     4,     4,     4,     4,     3,     3,     3,     3,\n",
      "            2,     2,     2,     2, 50289, 50289, 50289, 50289, 40335, 40335,\n",
      "        40335, 40335,   443,   443,   443,   443,    97,    97,    97,    97,\n",
      "            0,     0,     0,     0,     9,     9,     9,     9,     5,     5,\n",
      "            5,     5,   199,   199,   199,   199,  1170,  1170,  1170,  1170,\n",
      "          140,   140,   140,   140], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_next_batch(contexts, window_size, batch_size, epochs_count):\n",
    "    assert batch_size % (window_size * 2) == 0\n",
    "    central_words, contexts = zip(*contexts)\n",
    "    batch_size //= (window_size * 2)\n",
    "    \n",
    "    for epoch in range(epochs_count):\n",
    "        indices = np.arange(len(contexts))\n",
    "        np.random.shuffle(indices)\n",
    "        batch_begin = 0\n",
    "        while batch_begin < len(contexts):\n",
    "            batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
    "            batch_contexts, batch_centrals = [], []\n",
    "            for data_ind in batch_indices:\n",
    "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
    "                batch_contexts.extend(context)\n",
    "                batch_centrals.extend([central_word] * len(context))\n",
    "                \n",
    "            batch_begin += batch_size\n",
    "            yield torch.cuda.LongTensor(batch_contexts), torch.cuda.LongTensor(batch_centrals)\n",
    "\n",
    "print(next(get_next_batch(contexts, window_size=2, batch_size=64, epochs_count=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T18:24:16.113162Z",
     "start_time": "2020-04-11T18:24:16.105266Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_skipgram(model, contexts, batch_size = 256, epochs_count=10, save_path=\"model.pt\",\n",
    "                loss_every_nsteps=1000, lr=0.01, device_name=\"cuda\"):\n",
    "    \n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim \n",
    "    import time\n",
    "    \n",
    "    # слов: число контекстов (предложений) * длина окна\n",
    "    # [80, 32] - эмбеддинг длины 32 на 80 слов\n",
    "    # На выходе для функции потерь число слов*длина словаря\n",
    "    # После softmax [80, 112084] -> [80, 1]\n",
    "\n",
    "    #Trainable params: 7285460\n",
    "    #torch.Size([80])\n",
    "    #torch.Size([80, 32])\n",
    "    #torch.Size([80, 112084])\n",
    "    #torch.Size([80, 112084])\n",
    "    #torch.Size([80])\n",
    "    \n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    # устройство\n",
    "    device = torch.device(device_name)\n",
    "    # перенос модели на устройство\n",
    "    model = model.to(device)\n",
    "    # инициализация общих потерь\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    # выбор оптимизатора\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # выбор функции потерь\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "    \n",
    "    for step, (batch_contexts, batch_centrals) in enumerate(get_next_batch(contexts, window_size=2, batch_size=batch_size, epochs_count=epochs_count)):\n",
    "        logits = model(batch_centrals) # Прямой проход\n",
    "        loss = loss_function(logits, batch_contexts) # Подсчёт ошибки\n",
    "        loss.backward() # Подсчёт градиентов dL/dw\n",
    "        optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "        optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if step != 0 and step % loss_every_nsteps == 0:\n",
    "            print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    # Загрузка модели\n",
    "    #model = SkipGramModel(vocabulary.size, 32)\n",
    "    #model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "model_skipgram = SkipGramModel(vocabulary.size, 32)\n",
    "train_model_skipgram(model_skipgram, contexts, batch_size = 256, epochs_count=6, save_path=\"skipgram_v4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:12:06.161544Z",
     "start_time": "2020-04-12T18:12:06.095724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram = SkipGramModel(vocabulary.size, 32)\n",
    "model_skipgram.load_state_dict(torch.load('skipgram_v4.pt')) # текущая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPJxZwYgo2JH"
   },
   "source": [
    "## Базовые проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:12:07.057193Z",
     "start_time": "2020-04-12T18:12:06.162542Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "uh2McM2dTkVD",
    "outputId": "6edcc1f8-0058-4c59-df21-c58af464fecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['путин',\n",
       " 'гройсман',\n",
       " 'мединский',\n",
       " 'жириновский',\n",
       " 'лукин',\n",
       " 'владимир',\n",
       " 'президент',\n",
       " 'городецкий',\n",
       " 'чистюхин',\n",
       " 'маркин']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def most_similar(embeddings, vocabulary, word):\n",
    "    word_emb = embeddings[vocabulary.get_index(word)]\n",
    "    \n",
    "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
    "    top10 = np.argsort(similarities)[-10:]\n",
    "    \n",
    "    return [vocabulary.get_word(index) for index in reversed(top10)]\n",
    "\n",
    "embeddings = model_skipgram.embeddings.weight.cpu().data.numpy()\n",
    "most_similar(embeddings, vocabulary, 'путин')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07fU270Bo9Qk"
   },
   "source": [
    "Сделаем такую же визуализацию, какая была на прошлом семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "oAWj2Sf-Tmvy",
    "outputId": "a95ae850-daec-45d1-c4fe-3d30d8eab0cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-ir\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1105\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1105\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1105\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1105' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1105\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1105\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1105\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1105' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1105\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"6149569e-2d8d-4eb0-a15b-0ba828cbe299\" data-root-id=\"1107\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"4c68842d-8555-4d95-9546-52df0096bf37\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1116\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1120\",\"type\":\"Grid\"},{\"id\":\"1125\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1121\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1142\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1155\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1132\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1108\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1112\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1110\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1114\",\"type\":\"LinearScale\"}},\"id\":\"1107\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1157\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1122\",\"type\":\"BasicTicker\"}},\"id\":\"1121\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1157\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1112\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1114\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1130\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1161\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1163\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null},\"id\":\"1108\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1117\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1131\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1162\",\"type\":\"Selection\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1122\",\"type\":\"BasicTicker\"}},\"id\":\"1125\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"\\u0432\",\"\\u0438\",\"\\u043d\\u0430\",\"\\u00ab\",\"\\u00bb\",\"\\u0447\\u0442\\u043e\",\"\\u0441\",\"\\u043f\\u043e\",\"\\u2014\",\"\\u043d\\u0435\",\"\\u0438\\u0437\",\"\\u044d\\u0442\\u043e\\u043c\",\"\\u043e\\u0431\",\"\\u043e\",\"\\u043e\\u043d\",\"\\u0437\\u0430\",\"\\u0433\\u043e\\u0434\\u0430\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0438\",\"\\u043a\",\"\\u0435\\u0433\\u043e\",\"\\u0434\\u043b\\u044f\",\"\\u043a\\u0430\\u043a\",\"\\u0442\\u0430\\u043a\\u0436\\u0435\",\"\\u043e\\u0442\",\"\\u0430\",\"\\u044d\\u0442\\u043e\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u0435\\u0442\",\"\\u0434\\u043e\",\"\\u0433\\u043e\\u0434\\u0443\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\",\"\\u0441\\u0448\\u0430\",\"\\u0443\",\"\\u0432\\u043e\",\"\\u0432\\u0440\\u0435\\u043c\\u044f\",\"\\u0431\\u044b\\u043b\",\"\\u043f\\u0440\\u0438\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\",\"\\u0441\\u043e\",\"\\u0441\\u043b\\u043e\\u0432\\u0430\\u043c\",\"\\u0440\\u0443\\u0431\\u043b\\u0435\\u0439\",\"\\u0431\\u0443\\u0434\\u0435\\u0442\",\"\\u0435\\u0435\",\"\\u043e\\u043d\\u0430\",\"\\u043d\\u043e\",\"\\u0440\\u0430\\u043d\\u0435\\u0435\",\"\\u0438\\u0445\",\"\\u043e\\u043d\\u0438\",\"\\u0431\\u044b\\u043b\\u043e\",\"\\u0442\\u044b\\u0441\\u044f\\u0447\",\"\\u0431\\u043e\\u043b\\u0435\\u0435\",\"\\u0442\\u043e\\u0433\\u043e\",\"\\u0442\\u043e\\u043c\",\"\\u043c\\u044b\",\"\\u0431\\u044b\\u043b\\u0438\",\"\\u044f\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435\",\"\\u0432\\u0441\\u0435\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0439\",\"\\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\",\"\\u043f\\u043e\\u0434\",\"2016\",\"\\u0438\\u0437-\\u0437\\u0430\",\"\\u043b\\u0435\\u0442\",\"2017\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u044b\",\"\\u043c\\u0430\\u0440\\u0442\\u0430\",\"\\u043f\\u0440\\u043e\\u0446\\u0435\\u043d\\u0442\\u043e\\u0432\",\"\\u0447\\u0442\\u043e\\u0431\\u044b\",\"\\u0434\\u043e\\u043b\\u043b\\u0430\\u0440\\u043e\\u0432\",\"\\u0433\\u043b\\u0430\\u0432\\u0430\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\",\"\\u044d\\u0442\\u043e\\u0433\\u043e\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\",\"\\u0436\\u0435\",\"\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\",\"\\u0442\\u0430\\u043a\",\"\\u044f\\u043d\\u0432\\u0430\\u0440\\u044f\",\"\\u0438\\u043b\\u0438\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u044b\",\"\\u0440\\u0443\",\"\\u0442\\u043e\",\"\\u0435\\u0449\\u0435\",\"\\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\\u0438\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u043c\",\"\\u0431\\u044b\\u043b\\u0430\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u0430\",\"\\u043e\\u043a\\u043e\\u043b\\u043e\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\",\"\\u0444\\u0435\\u0432\\u0440\\u0430\\u043b\\u044f\",\"\\u043e\\u0434\\u043d\\u0430\\u043a\\u043e\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0438\",\"\\u043c\\u043e\\u0436\\u0435\\u0442\",\"\\u0443\\u0436\\u0435\",\"\\u043e\\u0434\\u0438\\u043d\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\",\"\\u0442\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043f\\u0440\\u043e\\u0446\\u0435\\u043d\\u0442\\u0430\",\"1\",\"10\",\"\\u0438\\u044e\\u043d\\u044f\",\"\\u0438\\u044e\\u043b\\u044f\",\"\\u043c\\u0430\\u044f\",\"\\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u043e\\u043d\\u043e\\u0432\",\"\\u043a\\u043e\\u0433\\u0434\\u0430\",\"\\u0430\\u043f\\u0440\\u0435\\u043b\\u044f\",\"\\u043f\\u0435\\u0440\\u0435\\u0434\\u0430\\u0435\\u0442\",\"\\u0435\\u0441\\u043b\\u0438\",\"\\u0431\\u0443\\u0434\\u0443\\u0442\",\"\\u0441\\u0430\\u0439\\u0442\\u0435\",\"\\u0434\\u0432\\u0430\",\"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\",\"the\",\"20\",\"\\u043b\\u0435\\u043d\\u0442\\u044b\",\"\\u043d\\u0438\\u0445\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u0435\\u0442\\u0441\\u044f\",\"\\u0433\\u0434\\u0435\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u043b\\u043e\\u0441\\u044c\",\"\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u0435\",\"\\u0432\\u0438\\u0434\\u0435\\u043e\",\"\\u0441\\u0435\\u043d\\u0442\\u044f\\u0431\\u0440\\u044f\",\"\\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0435\",\"\\u043d\\u043e\\u0432\\u043e\\u0441\\u0442\\u0438\",\"\\u0432\\u043b\\u0430\\u0441\\u0442\\u0438\",\"\\u0441\\u0443\\u0434\",\"\\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u0441\\u044f\",\"\\u0430\\u0432\\u0433\\u0443\\u0441\\u0442\\u0430\",\"\\u043a\\u0440\\u043e\\u043c\\u0435\",\"15\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u043e\\u043d\\u0430\",\"\\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f\",\"\\u0442\\u044b\\u0441\\u044f\\u0447\\u0438\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\",\"\\u0434\\u0435\\u043d\\u044c\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f\",\"\\u0440\\u0438\\u0430\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\\u0430\",\"\\u043e\\u0442\\u043c\\u0435\\u0447\\u0430\\u0435\\u0442\\u0441\\u044f\",\"\\u043f\\u0443\\u0442\\u0438\\u043d\",\"\\u0431\\u044b\\u0442\\u044c\",\"\\u0434\\u0432\\u0443\\u0445\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0445\",\"\\u0441\\u0442\\u0430\\u043b\\u043e\",\"\\u0433\\u043e\\u0434\",\"2\",\"\\u0445\\u043e\\u0434\\u0435\",\"\\u0435\\u043c\\u0443\",\"\\u0441\\u0432\\u043e\\u0435\\u0439\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\",\"\\u0447\\u0435\\u0440\\u0435\\u0437\",\"\\u0431\\u0435\\u0437\\u043e\\u043f\\u0430\\u0441\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0442\\u0440\\u0438\",\"\\u0431\\u0435\\u0437\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0445\",\"\\u0447\\u0435\\u043c\",\"\\u0447\\u0438\\u0441\\u043b\\u0435\",\"30\",\"\\u0432\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440\",\"\\u0432\\u0441\\u0435\\u0433\\u043e\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u0430\",\"\\u0441\\u0432\\u043e\\u044e\",\"\\u0435\\u0441\\u0442\\u044c\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u043e\\u043a\\u0442\\u044f\\u0431\\u0440\\u044f\",\"\\u0441\\u0440\\u0435\\u0434\\u0443\",\"\\u0432\\u0442\\u043e\\u0440\\u043d\\u0438\\u043a\",\"\\u043c\\u0438\\u0440\\u0430\",\"\\u043f\\u043e\\u043d\\u0435\\u0434\\u0435\\u043b\\u044c\\u043d\\u0438\\u043a\",\"\\u0434\\u043e\\u0431\\u0430\\u0432\\u0438\\u043b\",\"\\u0442\\u0430\\u0441\\u0441\",\"\\u0442\\u0435\\u0440\\u0440\\u0438\\u0442\\u043e\\u0440\\u0438\\u0438\",\"\\u043c\\u0435\\u0441\\u0442\\u043e\",\"12\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u044f\",\"\\u0441\\u0442\\u0430\\u043b\",\"\\u0447\\u0430\\u0441\\u0442\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0431\\u044b\",\"\\u0447\\u0435\\u0442\\u0432\\u0435\\u0440\\u0433\",\"\\u0434\\u043e\\u043c\\u0430\",\"\\u0438\\u0437\\u0434\\u0430\\u043d\\u0438\\u0435\",\"\\u0438\\u0437\\u0432\\u0435\\u0441\\u0442\\u043d\\u043e\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u044b\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439\",\"\\u0441\\u0441\\u044b\\u043b\\u043a\\u043e\\u0439\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u0435\",\"\\u0440\\u0430\\u0437\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438\",\"\\u0434\\u0435\\u043a\\u0430\\u0431\\u0440\\u044f\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u0438\",\"\\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\\u0430\",\"\\u044d\\u0442\\u043e\\u0442\",\"\\u0434\\u0435\\u043b\\u043e\",\"\\u043f\\u044f\\u0442\\u043d\\u0438\\u0446\\u0443\",\"2015\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u0430\\u0440\\u0434\\u0430\",\"14\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u0430\",\"3\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u0438\",\"\\u043d\\u0435\\u0433\\u043e\",\"\\u043c\\u043e\\u0433\\u0443\\u0442\",\"\\u0432\\u0441\\u0435\\u0445\",\"11\",\"\\u0441\\u043b\\u043e\\u0432\\u0430\",\"2018\",\"\\u0441\\u0440\\u0435\\u0434\\u0438\",\"\\u0442\\u0435\\u043c\",\"\\u0442\\u0440\\u0430\\u043c\\u043f\\u0430\",\"2014\",\"\\u0441\\u0435\\u0431\\u044f\",\"\\u0433\\u043b\\u0430\\u0432\\u044b\",\"\\u0440\\u0444\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u043e\\u0439\",\"\\u043f\\u043e\\u043a\\u0430\",\"\\u0442\\u0440\\u0430\\u043c\\u043f\",\"\\u0441\\u0438\\u0440\\u0438\\u0438\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\\u0438\",\"4\",\"\\u043d\\u0435\\u0442\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u043f\\u043e\\u0434\\u0447\\u0435\\u0440\\u043a\\u043d\\u0443\\u043b\",\"\\u0441\\u0432\\u044f\\u0437\\u0438\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u0438\\u0435\",\"\\u043d\\u043e\\u044f\\u0431\\u0440\\u044f\",\"25\",\"\\u043c\\u043e\\u0436\\u043d\\u043e\",\"\\u043f\\u0435\\u0440\\u0435\\u0434\",\"\\u043a\\u043e\\u043d\\u0446\\u0435\",\"\\u043e\\u0447\\u0435\\u043d\\u044c\",\"\\u0441\\u0435\\u0442\\u0438\",\"\\u0441\\u0435\\u0439\\u0447\\u0430\\u0441\",\"\\u043b\\u044e\\u0434\\u0435\\u0439\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0433\\u043e\",\"6\",\"\\u0440\\u0430\\u043c\\u043a\\u0430\\u0445\",\"\\u043f\\u0435\\u0440\\u0432\\u044b\\u0439\",\"18\",\"\\u0434\\u0440\\u0443\\u0433\\u0438\\u0445\",\"16\",\"\\u043d\\u0430\\u0434\",\"13\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439\",\"7\",\"17\",\"\\u043c\\u043e\\u043c\\u0435\\u043d\\u0442\",\"5\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u043c\",\"\\u0442\\u0430\\u043c\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u0438\",\"\\u0443\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u043a\\u043e\\u043c\\u0438\\u0442\\u0435\\u0442\\u0430\",\"\\u044d\\u0442\\u043e\\u0439\",\"\\u0438\\u043c\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u043d\\u043e\",\"\\u043d\\u0430\\u0441\\u0442\\u043e\\u044f\\u0449\\u0435\\u0435\",\"\\u043f\\u0438\\u0448\\u0435\\u0442\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u044b\",\"\\u0431\\u044b\\u0432\\u0448\\u0438\\u0439\",\"\\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u043c\\u043d\\u0435\\u043d\\u0438\\u044e\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\\u0435\",\"24\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0435\\u043d\\u0438\\u0438\",\"\\u043d\\u0430\\u0437\\u0432\\u0430\\u043b\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0430\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u044b\",\"9\",\"\\u0440\\u0435\\u0441\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u0438\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0435\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u0435\\u043b\",\"\\u0442\\u043e\\u0442\",\"\\u0432\\u043e\\u043f\\u0440\\u043e\\u0441\",\"\\u0432\\u043c\\u0435\\u0441\\u0442\\u0435\",\"\\u0441\\u0442\\u0430\\u043b\\u0438\",\"\\u044d\\u0442\\u0438\",\"\\u0440\\u0430\\u0439\\u043e\\u043d\\u0435\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\",\"19\",\"\\u0441\\u043c\\u0438\",\"23\",\"\\u0441\\u0435\\u0440\\u0433\\u0435\\u0439\",\"22\",\"\\u043f\\u043e\\u0447\\u0442\\u0438\",\"\\u0434\\u0435\\u0442\\u0435\\u0439\",\"\\u043f\\u044f\\u0442\\u044c\",\"21\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0435\",\"\\u0430\\u0433\\u0435\\u043d\\u0442\\u0441\\u0442\\u0432\\u043e\",\"\\u0434\\u043c\\u0438\\u0442\\u0440\\u0438\\u0439\",\"\\u043e\\u0434\\u043d\\u043e\\u0439\",\"\\u043e\\u0434\\u043d\\u043e\\u0433\\u043e\",\"\\u0441\\u043b\\u0443\\u0447\\u0430\\u0435\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u0430\\u0440\\u0434\\u043e\\u0432\",\"twitter\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\\u0430\",\"\\u0447\\u0430\\u0441\\u0442\\u044c\",\"\\u043e\\u0442\\u043c\\u0435\\u0447\\u0430\\u0435\\u0442\",\"\\u0442\\u043e\\u0433\\u0434\\u0430\",\"8\",\"\\u043f\\u043e\\u0433\\u0438\\u0431\\u043b\\u0438\",\"\\u043c\\u0432\\u0434\",\"\\u0436\\u0438\\u0437\\u043d\\u0438\",\"\\u043c\\u0435\\u0441\\u0442\\u0435\",\"\\u0441\\u0432\\u043e\\u0435\\u043c\",\"\\u0447\\u0435\\u0442\\u044b\\u0440\\u0435\",\"\\u0447\\u0430\\u0441\\u0442\\u0438\",\"\\u0432\\u0435\\u0434\\u043e\\u043c\\u0441\\u0442\\u0432\\u0430\",\"\\u0441\\u043e\\u0442\\u0440\\u0443\\u0434\\u043d\\u0438\\u043a\\u0438\",\"\\u043d\\u0430\\u0445\\u043e\\u0434\\u0438\\u0442\\u0441\\u044f\",\"\\u043f\\u043e\\u0440\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u0447\\u0435\\u0433\\u043e\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044e\",\"facebook\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0435\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\\u0430\",\"\\u0438\\u0441\\u0442\\u043e\\u0447\\u043d\\u0438\\u043a\",\"27\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\\u0438\",\"\\u043d\\u0438\",\"28\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0435\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u0430\",\"26\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\\u043d\",\"\\u0441\\u0432\\u043e\\u0438\\u0445\",\"\\u0437\\u0430\\u0442\\u0435\\u043c\",\"\\u043d\\u0430\\u0441\",\"100\",\"\\u0442\\u0430\\u043a\\u0438\\u043c\",\"\\u0441\\u0442\\u0430\\u043b\\u0430\",\"\\u0434\\u043d\\u044f\",\"\\u0443\\u0434\\u0430\\u043b\\u043e\\u0441\\u044c\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0435\",\"\\u043f\\u0440\\u0438\\u0432\\u043e\\u0434\\u0438\\u0442\",\"\\u0434\\u043e\\u043b\\u0436\\u0435\\u043d\",\"\\u043b\\u0438\",\"\\u043e\\u0431\\u0440\\u0430\\u0437\\u043e\\u043c\",\"\\u0434\\u0440\\u0443\\u0433\\u0438\\u0435\",\"\\u0443\\u0433\\u043e\\u043b\\u043e\\u0432\\u043d\\u043e\\u0435\",\"\\u0434\\u043e\\u043c\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\",\"\\u0441\\u0447\\u0438\\u0442\\u0430\\u0435\\u0442\",\"\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432\",\"\\u0430\\u0433\\u0435\\u043d\\u0442\\u0441\\u0442\\u0432\\u0430\",\"\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0442\\u0435\\u0447\\u0435\\u043d\\u0438\\u0435\",\"\\u0442\\u0440\\u0435\\u0445\",\"\\u0432\\u0442\\u043e\\u0440\\u043e\\u0439\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0430\",\"\\u043d\\u0430\\u043f\\u0438\\u0441\\u0430\\u043b\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044e\",\"\\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\",\"\\u0434\\u0438\\u0440\\u0435\\u043a\\u0442\\u043e\\u0440\",\"\\u043a\\u0430\\u0447\\u0435\\u0441\\u0442\\u0432\\u0435\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0430\",\"\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439\",\"\\u0441\\u0432\\u043e\\u0438\",\"news\",\"\\u043d\\u043e\\u0432\\u044b\\u0445\",\"\\u043d\\u043e\\u0432\\u044b\\u0439\",\"\\u0434\\u0435\\u043b\\u0430\",\"\\u0441\\u0432\\u043e\\u0435\\u0433\\u043e\",\"\\u0441\\u043e\\u0432\\u0435\\u0442\\u0430\",\"\\u043c\\u0438\\u0434\",\"\\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0435\\u0439\",\"\\u043a\\u0442\\u043e\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\\u0438\",\"\\u0438\\u0434\\u0435\\u0442\",\"\\u0434\\u0430\\u0436\\u0435\",\"\\u0435\\u0432\\u0440\\u043e\",\"50\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0432\\u044c\\u044e\",\"\\u0438\\u043d\\u0446\\u0438\\u0434\\u0435\\u043d\\u0442\",\"\\u0431\\u044b\\u0432\\u0448\\u0435\\u0433\\u043e\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\\u0430\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u0432\\u043d\\u0438\\u043c\\u0430\\u043d\\u0438\\u0435\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0435\",\"\\u043b\\u044e\\u0434\\u0438\",\"\\u0432\\u043f\\u0435\\u0440\\u0432\\u044b\\u0435\",\"\\u0432\\u0440\\u0435\\u043c\\u0435\\u043d\\u0438\",\"\\u043b\\u0438\\u0434\\u0435\\u0440\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u0438\",\"\\u043f\\u043e\\u0441\\u0442\",\"\\u043c\\u0430\\u0440\\u0442\\u0435\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u044f\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u044b\",\"\\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u044b\",\"\\u043f\\u043e\\u044f\\u0441\\u043d\\u0438\\u043b\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043d\\u043e\",\"\\u0434\\u043d\\u0435\\u0439\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0443\",\"\\u0432\\u0435\\u0440\\u0441\\u0438\\u0438\",\"\\u043f\\u0430\\u0440\\u0442\\u0438\\u0438\",\"\\u043c\\u0435\\u043d\\u044f\",\"\\u0434\\u0435\\u043a\\u0430\\u0431\\u0440\\u0435\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\\u0438\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u0438\",\"29\",\"\\u0438\\u0433\",\"\\u0438\\u0437\\u0434\\u0430\\u043d\\u0438\\u044f\",\"\\u0447\\u0438\\u0441\\u043b\\u043e\",\"\\u043c\\u0438\\u0440\\u0435\",\"\\u0433\\u0435\\u0440\\u043c\\u0430\\u043d\\u0438\\u0438\",\"\\u043f\\u0435\\u0441\\u043a\\u043e\\u0432\",\"\\u043e\\u043e\\u043d\",\"\\u0435\\u0439\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0439\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u043e\\u0433\\u043e\",\"\\u044f\\u043d\\u0432\\u0430\\u0440\\u0435\",\"\\u0441\\u043c\\u0435\\u0440\\u0442\\u0438\",\"\\u043f\\u043e\\u0440\\u044f\\u0434\\u043a\\u0430\",\"\\u0444\\u0435\\u0434\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\",\"\\u043e\\u0431\\u043d\\u0430\\u0440\\u0443\\u0436\\u0438\\u043b\\u0438\",\"\\u0434\\u0432\\u0435\",\"\\u0434\\u0435\\u043d\\u044c\\u0433\\u0438\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u044c\\u044e\",\"\\u0441\\u0431\\u043e\\u0440\\u043d\\u043e\\u0439\",\"\\u043f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u044b\",\"\\u0434\\u0435\\u043f\\u0443\\u0442\\u0430\\u0442\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0440\\u0435\\u043b\\u0438\\u0437\\u0435\",\"\\u043e\\u0447\\u0435\\u0440\\u0435\\u0434\\u044c\",\"\\u0437\\u0430\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\\u0438\",\"\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\",\"\\u0438\\u0442\\u043e\\u0433\\u0430\\u043c\",\"\\u0433\\u0430\\u0437\\u0435\\u0442\\u0430\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0444\\u0430\\u043a\\u0441\",\"\\u0434\\u0435\\u043b\",\"\\u0441\\u0443\\u0434\\u0430\",\"\\u0440\\u0430\\u0437\\u0432\\u0438\\u0442\\u0438\\u044f\",\"\\u0441\\u043b\\u0443\\u0436\\u0431\\u044b\",\"\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\\u0430\",\"\\u043c\\u0435\\u0441\\u0442\\u0430\",\"\\u0441\\u0438\\u043b\",\"\\u0443\\u0447\\u0435\\u043d\\u044b\\u0435\",\"\\u043f\\u0440\\u043e\\u0439\\u0434\\u0435\\u0442\",\"\\u043a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432\",\"\\u0441\\u043e\\u0442\\u0440\\u0443\\u0434\\u043d\\u0438\\u043a\\u043e\\u0432\",\"\\u043a\\u043e\\u0440\\u0440\\u0435\\u0441\\u043f\\u043e\\u043d\\u0434\\u0435\\u043d\\u0442\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\\u0435\",\"\\u0432\\u043e\\u0441\\u043a\\u0440\\u0435\\u0441\\u0435\\u043d\\u044c\\u0435\",\"\\u0447\\u0430\\u0441\\u043e\\u0432\",\"\\u043c\\u043d\\u0435\",\"\\u0444\\u0435\\u0432\\u0440\\u0430\\u043b\\u0435\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0438\\u0446\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u0441\\u043a\\u043e\\u0439\",\"\\u043d\\u043e\\u0432\\u043e\\u0433\\u043e\",\"\\u043f\\u043e\\u044d\\u0442\\u043e\\u043c\\u0443\",\"\\u043d\\u043e\\u0432\\u043e\\u0439\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u043d\\u043e\\u0432\\u043e\\u0441\\u0442\\u0435\\u0439\",\"\\u043a\\u0440\\u044b\\u043c\\u0430\",\"\\u0438\\u043c\\u0435\\u043d\\u043d\\u043e\",\"\\u044d\\u0442\\u0443\",\"\\u043c\\u0435\\u043d\\u0435\\u0435\",\"\\u043a\\u043d\\u0434\\u0440\",\"\\u0440\\u0435\\u0447\\u044c\",\"\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u0442\\u0430\\u043a\\u043e\\u0435\",\"\\u0437\\u0430\\u044f\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u043e\\u043b\\u043d\\u043e\\u0441\\u0442\\u044c\\u044e\",\"\\u043d\\u0430\\u0437\\u0430\\u0434\",\"\\u043a\\u0440\\u044b\\u043c\",\"\\u0444\\u0440\\u0430\\u043d\\u0446\\u0438\\u0438\",\"\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0438\",\"\\u0430\\u0434\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u043d\\u0435\\u043c\",\"\\u043f\\u0443\\u0442\\u0438\\u043d\\u0430\",\"\\u0442\\u0430\\u043a\\u0438\\u0435\",\"reuters\",\"\\u0444\\u043e\\u0442\\u043e\",\"\\u0431\\u0430\\u043d\\u043a\\u0430\",\"\\u043d\\u0435\\u0435\",\"\\u044d\\u0442\\u0438\\u0445\",\"\\u0441\\u0432\\u043e\\u0439\",\"\\u043d\\u043e\\u0432\\u044b\\u0435\",\"\\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0438\\u043b\",\"\\u043e\\u0434\\u043d\\u0430\",\"\\u043e\\u0431\\u0432\\u0438\\u043d\\u0435\\u043d\\u0438\\u044f\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u0443\\u044e\",\"\\u0434\\u043e\\u043d\\u0431\\u0430\\u0441\\u0441\\u0435\",\"\\u0442\\u0435\\u043b\\u0435\\u043a\\u0430\\u043d\\u0430\\u043b\",\"\\u043f\\u043e\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0443\",\"\\u043b\\u0435\\u043d\\u0442\\u0435\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438\",\"\\u043d\\u0435\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435\",\"\\u0443\\u043a\",\"40\",\"\\u043d\\u043e\\u044f\\u0431\\u0440\\u0435\",\"\\u0442\\u0430\\u043a\\u0438\\u0445\",\"\\u044f\\u043a\\u043e\\u0431\\u044b\",\"\\u043a\\u043e\\u043c\\u0430\\u043d\\u0434\\u044b\",\"\\u0432\\u0435\\u043b\\u0438\\u043a\\u043e\\u0431\\u0440\\u0438\\u0442\\u0430\\u043d\\u0438\\u0438\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043b\",\"\\u0438\\u043c\\u0435\\u043d\\u0438\",\"\\u044d\\u0442\\u0438\\u043c\",\"31\",\"\\u043e\\u0440\\u0443\\u0436\\u0438\\u044f\",\"\\u0441\\u043f\\u0438\\u0441\\u043e\\u043a\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\\u0430\",\"\\u0433\\u043e\\u0441\\u0434\\u0443\\u043c\\u044b\",\"\\u0448\\u0435\\u0441\\u0442\\u044c\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u044b\",\"\\u043d\\u0435\\u0439\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0438\",\"\\u043f\\u0440\\u043e\\u0441\\u0442\\u043e\",\"\\u0430\\u043d\\u0434\\u0440\\u0435\\u0439\",\"\\u0441\\u0430\\u043c\",\"\\u0441\\u043b\\u0435\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0433\\u043e\",\"\\u0441\\u0440\\u043e\\u043a\",\"\\u043f\\u0435\\u0440\\u0438\\u043e\\u0434\",\"\\u0443\\u043b\\u0438\\u0446\\u0435\",\"\\u043d\\u0438\\u043c\",\"\\u0438\\u043c\\u0435\\u0435\\u0442\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\",\"\\u0442\\u0430\\u043a\\u043e\\u0439\",\"\\u043d\\u0443\\u0436\\u043d\\u043e\",\"\\u0442\\u0443\\u0440\\u0446\\u0438\\u0438\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u0435\\u043a\\u0440\\u0435\\u0442\\u0430\\u0440\\u044c\",\"\\u043e\\u0431\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0430\",\"\\u0430\\u043f\\u0440\\u0435\\u043b\\u0435\",\"\\u0447\\u0435\\u043c\\u043f\\u0438\\u043e\\u043d\\u0430\\u0442\\u0430\",\"\\u043c\\u0435\\u0440\\u044b\",\"\\u0442\\u0435\\u0445\",\"\\u043f\\u0440\\u0430\\u0432\\u0430\",\"\\u043e\\u0444\\u0438\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u044b\\u0439\",\"\\u043a\\u0438\\u0435\\u0432\",\"\\u0434\\u0435\\u043b\\u0443\",\"\\u043f\\u0440\\u0438\\u0447\\u0438\\u043d\\u043e\\u0439\",\"\\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0445\\u0440\\u0430\\u043d\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\",\"\\u0438\\u043d\\u043e\\u0441\\u0442\\u0440\\u0430\\u043d\\u043d\\u044b\\u0445\",\"\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u043f\\u043e\\u0442\\u043e\\u043c\\u0443\",\"\\u0432\\u043e\\u0437\\u0431\\u0443\\u0436\\u0434\\u0435\\u043d\\u043e\",\"\\u043f\\u043e\\u043c\\u0438\\u043c\\u043e\",\"\\u0441\\u043e\\u0431\\u043e\\u0439\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u0438\",\"\\u043a\\u0438\\u0435\\u0432\\u0435\",\"2016-\\u0433\\u043e\",\"\\u043f\\u0440\\u0438\\u043c\\u0435\\u0440\\u043d\\u043e\",\"\\u0441\\u0434\\u0435\\u043b\\u0430\\u0442\\u044c\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u043e\",\"\\u0441\\u0443\\u0431\\u0431\\u043e\\u0442\\u0443\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u043b\\u043e\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u0430\",\"\\u0441\\u0435\\u043d\\u0442\\u044f\\u0431\\u0440\\u0435\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\",\"\\u0441\\u043b\\u0435\\u0434\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u044f\",\"\\u043d\\u0430\\u0448\\u043b\\u0438\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\",\"\\u0440\\u043e\\u0441\\u0442\",\"\\u043c\\u0430\\u0435\",\"\\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f\",\"\\u0441\\u0430\\u043c\\u044b\\u0445\",\"\\u0432\\u044b\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0439\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u043e\\u0433\\u043e\",\"\\u043d\\u043e\\u0447\\u044c\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0438\",\"\\u043f\\u044f\\u0442\\u0438\",\"\\u0440\\u0435\\u0434\\u0430\\u043a\\u0446\\u0438\\u044e\",\"\\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043b\\u0438\\u0448\\u044c\",\"\\u043f\\u043e\\u0437\\u0434\\u043d\\u0435\\u0435\",\"\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u044b\",\"\\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u043a\\u043e\\u043b\\u0438\\u0447\\u0435\\u0441\\u0442\\u0432\\u043e\",\"\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u0430\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0430\\u044f\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\\u0435\\u0432\",\"\\u0440\\u0435\\u0431\\u0435\\u043d\\u043a\\u0430\",\"\\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0445\",\"\\u0434\\u0440\\u0443\\u0433\\u043e\\u0439\",\"\\u0441\\u0432\\u043e\\u0435\",\"\\u043f\\u043e\\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u043b\\u0438\",\"ru\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u043e\\u0432\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u0432\\u043e\\u0439\\u043d\\u044b\",\"\\u0440\\u044f\\u0434\",\"\\u043b\\u0438\\u0446\",\"\\u0447\\u0435\\u0442\\u044b\\u0440\\u0435\\u0445\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u043d\\u0438\\u043a\\u043e\\u0432\",\"\\u0435\\u0441\",\"\\u0441\\u0447\\u0438\\u0442\\u0430\\u044e\\u0442\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0439\",\"\\u044d\\u043a\\u0441\\u043f\\u0435\\u0440\\u0442\\u044b\",\"\\u0441\\u0430\\u043d\\u043a\\u0446\\u0438\\u0438\",\"\\u043d\\u0435\\u043e\\u0431\\u0445\\u043e\\u0434\\u0438\\u043c\\u043e\",\"\\u0441\\u0435\\u0431\\u0435\",\"\\u043e\\u0434\\u043d\\u0438\\u043c\",\"\\u043d\\u0430\\u0437\\u0432\\u0430\\u043b\\u0438\",\"\\u0435\\u0432\\u0440\\u043e\\u043f\\u044b\",\"\\u044d\\u0442\\u0430\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u044c\",\"\\u0441\\u0442\\u0430\\u043d\\u0435\\u0442\",\"\\u043d\\u0430\\u043c\",\"\\u0434\\u043e\\u043d\\u0430\\u043b\\u044c\\u0434\\u0430\",\"\\u043e\\u043a\\u0442\\u044f\\u0431\\u0440\\u0435\",\"\\u0441\\u0430\\u043c\\u044b\\u043c\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u043b\\u0443\\u0436\\u0431\\u0435\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\",\"\\u0434\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u044f\",\"\\u043e\\u0442\\u043a\\u0430\\u0437\\u0430\\u043b\\u0441\\u044f\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0435\\u0434\\u0430\\u0442\\u0435\\u043b\\u044c\",\"\\u043c\\u0438\\u043d\\u043e\\u0431\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\\u0430\",\"\\u0440\\u043e\\u043b\\u0438\\u043a\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0435\",\"s\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\\u044b\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u043b\",\"\\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0438\\u0445\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u0433\\u043e\",\"2013\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u043c\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u0438\",\"...\",\"\\u043f\\u043b\\u0430\\u043d\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\",\"\\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0430\",\"\\u0442\\u0435\\u043f\\u0435\\u0440\\u044c\",\"\\u043e\\u0431\\u044a\\u044f\\u0432\\u0438\\u043b\",\"\\u043e\\u043f\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0435\\u0439\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\\u0430\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u0430\\u0445\",\"\\u0441\\u0430\\u043c\\u043e\\u043b\\u0435\\u0442\",\"\\u0430\\u043a\\u0446\\u0438\\u0438\",\"daily\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044f\",\"\\u043f\\u043e\\u0437\\u0436\\u0435\",\"\\u0434\\u043e\\u043c\\u0435\",\"\\u0441\\u0447\\u0435\\u0442\",\"\\u043d\\u0435\\u0441\\u043c\\u043e\\u0442\\u0440\\u044f\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\\u0438\",\"\\u0432\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440\\u0430\",\"\\u0441\\u043f\\u0435\\u0446\\u0438\\u0430\\u043b\\u0438\\u0441\\u0442\\u044b\",\"\\u0441\\u0447\\u0435\\u0442\\u043e\\u043c\",\"\\u0440\\u0430\\u0437\\u043c\\u0435\\u0440\\u0435\",\"\\u0441\\u0432\\u043e\\u0438\\u043c\",\"\\u0441\\u0430\\u043d\\u043a\\u0446\\u0438\\u0439\",\"\\u0434\\u043d\\u0440\",\"\\u0440\\u044b\\u043d\\u043a\\u0435\",\"\\u0434\\u0432\\u043e\\u0435\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\\u0430\",\"\\u0437\\u0430\\u0434\\u0435\\u0440\\u0436\\u0430\\u043d\",\"instagram\",\"\\u043f\\u0440\\u0438\\u0437\\u0432\\u0430\\u043b\",\"\\u043f\\u0440\\u0438\\u043c\",\"\\u0430\\u043a\\u0442\\u0435\\u0440\",\"\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0439\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u044b\",\"\\u043c\\u043d\\u043e\\u0433\\u0438\\u0435\",\"200\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u043e\\u0439\",\"\\u0438\\u044e\\u043d\\u0435\",\"\\u0433\\u043e\\u0434\\u044b\",\"\\u043c\\u0430\\u0448\\u0438\\u043d\\u044b\",\"\\u0437\\u0430\\u043c\\u0435\\u0441\\u0442\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u043d\\u0438\\u0447\\u0435\\u0433\\u043e\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0435\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u0438\\u043d\\u0441\\u0442\\u0432\\u043e\",\"\\u0432\\u0438\\u0434\\u0435\",\"\\u043d\\u0430\\u0445\\u043e\\u0434\\u044f\\u0442\\u0441\\u044f\",\"\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430\",\"\\u0430\\u0440\\u043c\\u0438\\u0438\",\"\\u0432\\u0441\\u0435\\u043c\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u043e\\u043c\",\"\\u0440\\u0430\\u0441\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435\",\"\\u0434\\u043e\\u043d\\u0430\\u043b\\u044c\\u0434\",\"\\u043e\\u0434\\u043d\\u043e\\u043c\",\"\\u0432\\u043b\\u0430\\u0441\\u0442\\u0435\\u0439\",\"\\u0441\\u043e\\u0447\\u0438\",\"\\u0438\\u0433\\u0440\\u044b\",\"\\u043f\\u0440\\u0430\\u0432\\u043e\",\"\\u043f\\u043e\\u0440\\u0442\\u0430\\u043b\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0445\",\"\\u043d\\u0430\\u0442\\u043e\",\"\\u0432\\u043e\\u0448\\u043b\\u0438\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u0439\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0435\\u0439\\u0441\\u043a\\u0438\\u0435\",\"\\u043b\\u0438\\u0434\\u0435\\u0440\\u0430\",\"\\u0433\\u0430\\u0437\\u0430\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0433\\u043e\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\\u0435\",\"\\u0438\\u044e\\u043b\\u0435\",\"\\u0440\\u0430\\u0437\\u0430\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u0434\\u0435\\u043d\\u0438\\u044f\",\"\\u0444\\u0430\\u043a\\u0442\\u0443\",\"\\u043c\\u0438\\u043d\\u0443\\u0442\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u043b\\u0438\",\"\\u0441\\u0443\\u043c\\u043c\\u0443\",\"\\u043f\\u043e\\u043b\\u0438\\u0442\\u0438\\u043a\\u0438\",\"\\u043e\\u043a\\u0430\\u0437\\u0430\\u043b\\u0441\\u044f\",\"\\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0435\",\"\\u0434\\u0432\\u0438\\u0436\\u0435\\u043d\\u0438\\u044f\",\"\\u043c\\u0430\\u0442\\u0447\\u0435\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u0434\\u043d\\u0435\\u043c\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u043c\",\"\\u0441\\u0432\\u043e\\u0431\\u043e\\u0434\\u044b\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\\u043e\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\",\"\\u043c\\u043e\\u0434\\u0435\\u043b\\u044c\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u0442\\u044c\",\"\\u043d\\u0430\\u0438\\u0431\\u043e\\u043b\\u0435\\u0435\",\"\\u043c\\u043e\\u0434\\u0435\\u043b\\u0438\",\"\\u0446\\u0431\",\"\\u043f\\u0440\\u043e\\u043a\\u043e\\u043c\\u043c\\u0435\\u043d\\u0442\\u0438\\u0440\\u043e\\u0432\\u0430\\u043b\",\"\\u044d\\u0442\\u043e\\u043c\\u0443\",\"youtube\",\"\\u043c\\u043d\\u043e\\u0433\\u043e\",\"\\u044f\\u0432\\u043b\\u044f\\u044e\\u0442\\u0441\\u044f\",\"\\u043a\\u0430\\u0436\\u0434\\u044b\\u0439\",\"\\u0442\\u043e\\u043d\\u043d\",\"00\",\"\\u043a\\u043e\\u043d\\u0446\\u0430\",\"\\u0444\\u0438\\u043b\\u044c\\u043c\\u0430\",\"\\u0437\\u0434\\u0430\\u043d\\u0438\\u044f\",\"\\u043f\\u0440\\u043e\\u0432\\u0438\\u043d\\u0446\\u0438\\u0438\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\",\"\\u043f\\u043e\\u0441\\u0442\\u0443\\u043f\\u0438\\u0432\\u0448\\u0435\\u043c\",\"\\u043e\\u0434\\u0435\\u0436\\u0434\\u044b\",\"\\u043d\\u0435\\u043e\\u0434\\u043d\\u043e\\u043a\\u0440\\u0430\\u0442\\u043d\\u043e\",\"\\u0441\\u0435\\u0432\\u0435\\u0440\\u043d\\u043e\\u0439\",\"\\u0433\\u043e\\u0434\\u0430\\u0445\",\"\\u0430\\u0432\\u0433\\u0443\\u0441\\u0442\\u0435\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u0441\\u0442\\u0438\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u043c\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u043b\\u0443\\u0436\\u0431\\u0430\",\"\\u0431\\u043b\\u0430\\u0433\\u043e\\u0434\\u0430\\u0440\\u044f\",\"\\u0441\\u0435\\u043c\\u044c\",\"\\u0432\\u043e\\u0441\\u0435\\u043c\\u044c\",\"\\u043c\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u0441\\u043a\\u043e\\u043d\\u0447\\u0430\\u043b\\u0441\\u044f\",\"\\u043c\\u0435\\u0440\\u043e\\u043f\\u0440\\u0438\\u044f\\u0442\\u0438\\u044f\",\"\\u0443\\u0442\\u043e\\u0447\\u043d\\u0438\\u043b\",\"60\",\"\\u0433\\u043b\\u0430\\u0432\\u043d\\u044b\\u0439\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0430\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\",\"\\u0440\\u0430\\u043a\\u0435\\u0442\\u044b\",\"\\u0441\\u0442\\u043e\\u043b\\u0438\\u0446\\u044b\",\"\\u043e\\u0431\\u044a\\u0435\\u043c\",\"\\u0444\\u043e\\u043d\\u0434\\u0430\",\"\\u0444\\u0438\\u043b\\u044c\\u043c\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0435\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0442\\u044c\",\"\\u0441\\u0430\\u043c\\u043e\\u043b\\u0435\\u0442\\u0430\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0435\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u0438\\u0442\\u0441\\u044f\",\"\\u043a\\u043b\\u0443\\u0431\\u0430\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u043e\\u0439\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0443\",\"\\u0441\\u043a\\u0440\",\"\\u043f\\u0440\\u0438\\u0437\\u043d\\u0430\\u043b\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\",\"\\u043d\\u0430\\u0441\\u0435\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u0441\\u0442\\u043e\\u043b\\u0438\\u0446\\u0435\",\"\\u043a\\u043e\\u043d\\u0444\\u043b\\u0438\\u043a\\u0442\\u0430\",\"\\u043f\\u043e\\u043e\\u0431\\u0435\\u0449\\u0430\\u043b\",\"\\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430\",\"500\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\\u0430\",\"\\u0431\\u0430\\u043d\\u043a\",\"\\u0446\\u0435\\u043b\\u044c\\u044e\",\"2012\",\"\\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u044b\",\"\\u0443\\u0440\\u043e\\u0432\\u043d\\u0435\",\"\\u0443\\u043c\\u0435\\u0440\",\"\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u043a\\u0432\\u0430\\u0434\\u0440\\u0430\\u0442\\u043d\\u044b\\u0445\",\"\\u043d\\u0430\\u043f\\u0440\\u0438\\u043c\\u0435\\u0440\",\"\\u0432\\u0435\\u0447\\u0435\\u0440\\u043e\\u043c\",\"\\u043b\\u0438\\u043d\\u0438\\u0438\",\"\\u043f\\u0430\\u0441\\u0441\\u0430\\u0436\\u0438\\u0440\\u043e\\u0432\",\"\\u0441\\u0442\\u0440\\u043e\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u0434\\u0435\\u043d\\u0435\\u0433\",\"\\u0444\\u0441\\u0431\",\"\\u043d\\u0435\\u0444\\u0442\\u0438\",\"\\u0441\\u0440\\u0430\\u0437\\u0443\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u043e\\u0432\",\"\\u0438\\u043c\\u044f\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0445\",\"\\u0431\\u0440\\u0435\\u043d\\u0434\\u0430\",\"\\u0436\\u0438\\u0437\\u043d\\u044c\",\"\\u0436\\u0438\\u043b\\u044c\\u044f\",\"\\u043d\\u0438\\u043a\\u0442\\u043e\",\"\\u0441\\u0440\\u0430\\u0432\\u043d\\u0435\\u043d\\u0438\\u044e\",\"\\u0432\\u044b\\u0440\\u0430\\u0437\\u0438\\u043b\",\"\\u043e\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438\\u0441\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u043e\\u0439\",\"\\u0432\\u043a\\u043b\\u044e\\u0447\\u0430\\u044f\",\"\\u043a\\u043e\\u043c\\u0438\\u0442\\u0435\\u0442\",\"\\u0440\\u0443\\u043a\\u043e\\u0432\\u043e\\u0434\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u0438\\u044f\",\"\\u043f\\u0440\\u0435\\u0441\\u0442\\u0443\\u043f\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u043e\\u043d\\u043e\",\"\\u043a\\u0438\\u0435\\u0432\\u0430\",\"\\u0442\\u0443\\u0440\\u0438\\u0441\\u0442\\u043e\\u0432\",\"\\u0448\\u0442\\u0430\\u0442\",\"\\u043f\\u0440\\u043e\\u0438\\u0441\\u0448\\u0435\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0435\",\"\\u0434\\u043e\\u043d\\u0435\\u0446\\u043a\\u043e\\u0439\",\"\\u0442\\u0435\\u043b\\u0435\\u043a\\u0430\\u043d\\u0430\\u043b\\u0430\",\"\\u0441\\u0442\\u043e\\u0438\\u0442\",\"\\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0430\",\"\\u0431\\u043e\\u0435\\u0432\\u0438\\u043a\\u043e\\u0432\",\"\\u0440\\u0435\\u0448\\u0438\\u043b\",\"\\u0441\\u043c\\u043e\\u0433\\u0443\\u0442\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0439\",\"\\u043c\\u0430\\u0440\\u043a\\u0438\",\"\\u0440\\u0435\\u0436\\u0438\\u043c\\u0430\",\"\\u0441\\u043f\\u0443\\u0441\\u0442\\u044f\",\"\\u0433\\u0443\\u0431\\u0435\\u0440\\u043d\\u0430\\u0442\\u043e\\u0440\",\"\\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u0443\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043d\",\"\\u043d\\u043e\\u0432\\u0443\\u044e\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u0430\",\"\\u043a\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u044b\",\"\\u0443\\u0440\\u043e\\u0432\\u0435\\u043d\\u044c\",\"\\u0442\\u0435\",\"\\u0440\\u0430\\u0434\\u044b\",\"\\u043b\\u0435\\u043d\\u0442\\u0430\",\"\\u043a\\u043e\\u043b\\u043b\\u0435\\u043a\\u0446\\u0438\\u044e\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0430\\u044f\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u0442\\u043e\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b\\u0430\",\"\\u0432\\u043e\\u043e\\u0440\\u0443\\u0436\\u0435\\u043d\\u043d\\u044b\\u0445\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0445\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u043b\",\"\\u043b\\u0438\\u0431\\u043e\",\"\\u043f\\u0435\\u0440\\u0435\\u0433\\u043e\\u0432\\u043e\\u0440\\u044b\",\"\\u043f\\u043b\\u0430\\u043d\\u0438\\u0440\\u0443\\u0435\\u0442\",\"\\u0441\\u0438\\u043b\\u044b\",\"\\u043e\\u0431\\u044a\\u044f\\u0441\\u043d\\u0438\\u043b\",\"\\u043a\\u0440\\u0435\\u043c\\u043b\\u044f\",\"\\u0438\\u0433\\u043e\\u0440\\u044c\",\"\\u043b\\u0438\\u0433\\u0438\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u0443\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u044e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u043a\\u0443\",\"\\u0438\\u0442\\u043e\\u0433\\u0435\",\"\\u0434\\u043e\\u043c\\u043e\\u0432\",\"\\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u044c\",\"\\u0446\\u0435\\u043d\\u044b\",\"\\u044e\\u0436\\u043d\\u043e\\u0439\",\"\\u043f\\u043e\\u0440\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u0439\",\"\\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0438\\u043b\\u0438\",\"\\u0437\\u0434\\u0435\\u0441\\u044c\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u043e\\u0439\",\"\\u043c\\u0435\\u0442\\u0440\\u043e\",\"\\u0434\\u0442\\u043f\",\"\\u043a\\u0440\\u044b\\u043c\\u0443\",\"\\u043a\\u0443\\u043b\\u044c\\u0442\\u0443\\u0440\\u044b\",\"300\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0443\",\"\\u0442\\u0435\\u0440\\u0440\\u0438\\u0442\\u043e\\u0440\\u0438\\u044e\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0443\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u044f\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u043f\\u043e\\u044f\\u0432\\u0438\\u043b\\u0430\\u0441\\u044c\",\"\\u0443\\u0433\\u043e\\u043b\\u043e\\u0432\\u043d\\u043e\\u0433\\u043e\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u044b\",\"\\u0441\\u0430\\u043d\\u043a\\u0442-\\u043f\\u0435\\u0442\\u0435\\u0440\\u0431\\u0443\\u0440\\u0433\\u0435\",\"\\u043a\\u043e\\u043d\\u0444\\u043b\\u0438\\u043a\\u0442\",\"\\u043d\\u0438\\u043a\\u043e\\u0433\\u0434\\u0430\",\"\\u0432\\u044b\\u0448\\u0435\\u043b\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\\u0430\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u0435\\u0434\\u0448\\u0435\\u0433\\u043e\",\"\\u0440\\u044f\\u0434\\u043e\\u043c\",\"\\u0434\\u0438\\u0440\\u0435\\u043a\\u0442\\u043e\\u0440\\u0430\",\"\\u043e\\u0431\\u0449\\u0435\\u0439\",\"\\u0443\\u043d\\u0438\\u0432\\u0435\\u0440\\u0441\\u0438\\u0442\\u0435\\u0442\\u0430\",\"\\u0431\\u0440\\u0435\\u043d\\u0434\",\"\\u0432\\u0442\\u043e\\u0440\\u043e\\u043c\",\"\\u0438\\u0441\\u0442\\u043e\\u0447\\u043d\\u0438\\u043a\\u0438\",\"\\u0444\\u043e\\u0442\\u043e\\u0433\\u0440\\u0430\\u0444\\u0438\\u0438\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\\u043d\\u0435\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u0438\\u0440\\u043e\\u0432\\u043a\\u0438\",\"\\u043c\\u043e\\u043a\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0435\\u0440\\u0441\\u0442\\u0432\\u0430\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430\",\"\\u043c\\u043e\\u0433\\u043b\\u0438\",\"\\u043b\\u0435\\u0442\\u043e\\u043c\",\"\\u0441\\u043e\\u044e\\u0437\\u0430\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u0442\\u044c\",\"\\u043f\\u0435\\u0440\\u0432\\u0443\\u044e\",\"\\u043e\\u0440\\u0443\\u0436\\u0438\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u0441\\u043a\\u043e\\u0433\\u043e\",\"mail\",\"\\u0441\\u0430\\u0430\\u043a\\u0430\\u0448\\u0432\\u0438\\u043b\\u0438\",\"\\u0440\\u0443\\u0431\\u043b\\u044f\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u0435\\u0439\",\"\\u043f\\u043e\\u0433\\u0438\\u0431\",\"\\u0438\\u0441\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f\",\"\\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0438\",\"\\u0432\\u0430\\u0448\\u0438\\u043d\\u0433\\u0442\\u043e\\u043d\",\"\\u043f\\u0435\\u0440\\u0432\\u044b\\u0435\",\"\\u0437\\u0430\\u043f\\u0440\\u0435\\u0449\\u0435\\u043d\\u0430\",\"\\u043f\\u043e\\u0431\\u0435\\u0434\\u044b\",\"\\u043e\\u0431\\u0432\\u0438\\u043d\\u0438\\u043b\\u0438\",\"\\u0432\\u0441\\u0435\\u0439\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u044e\",\"\\u0441\\u0442\\u0430\\u043d\\u0446\\u0438\\u0438\",\"\\u0441\\u0434\\u0435\\u043b\\u0430\\u043b\",\"\\u0438\\u0441\\u043b\\u0430\\u043c\\u0441\\u043a\\u043e\\u0435\",\"\\u043f\\u0440\\u043e\\u0445\\u043e\\u0434\\u0438\\u0442\",\"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u0430\\u043b\",\"\\u0447\\u043b\\u0435\\u043d\\u043e\\u0432\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0439\",\"\\u043e\\u0431\\u044a\\u0435\\u043a\\u0442\\u043e\\u0432\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u043e\",\"\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0445\",\"\\u0438\\u043d\\u0446\\u0438\\u0434\\u0435\\u043d\\u0442\\u0430\",\"\\u0432\\u043e\\u043a\\u0440\\u0443\\u0433\",\"\\u0433\\u043b\\u0430\\u0432\\u043d\\u043e\\u0433\\u043e\",\"\\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u0439\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u043e\\u043c\",\"\\u0443\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u044f\",\"\\u0441\\u0435\\u0440\\u0438\\u0438\",\"\\u0440\\u0430\\u0439\\u043e\\u043d\\u0430\",\"\\u043b\\u0438\\u0446\\u0430\",\"\\u0440\\u044b\\u043d\\u043a\\u0430\",\"of\",\"\\u0432\\u043a\\u043e\\u043d\\u0442\\u0430\\u043a\\u0442\\u0435\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u044f\",\"\\u0431\\u0435\\u043b\\u043e\\u0433\\u043e\",\"\\u0443\\u0434\\u0430\\u0440\",\"\\u043f\\u043e\\u0434\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u044c\\u0435\",\"\\u0432\\u043e\\u043f\\u0440\\u043e\\u0441\\u044b\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u0441\\u0430\\u043c\\u043e\\u0439\",\"\\u0432\\u0441\\u0435\\u0433\\u0434\\u0430\",\"\\u0440\\u043e\\u043b\\u044c\",\"\\u0441\\u0442\\u0440\\u043e\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u0430\",\"\\u043d\\u0438\\u043a\\u0430\\u043a\\u0438\\u0445\",\"\\u0441\\u0435\\u0440\\u0435\\u0434\\u0438\\u043d\\u0435\",\"\\u0442\\u0435\\u043b\\u043e\",\"\\u0448\\u0435\\u0441\\u0442\\u0438\",\"\\u0441\\u0435\\u043c\\u044c\\u0438\",\"\\u043f\\u043e\\u044f\\u0432\\u0438\\u043b\\u043e\\u0441\\u044c\",\"\\u0434\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\\u044b\",\"\\u0432\\u0435\\u0441\\u0442\\u0438\",\"\\u0443\\u0431\\u0438\\u0439\\u0441\\u0442\\u0432\\u043e\",\"\\u0430\\u0432\\u0438\\u0430\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0438\",\"\\u0441\\u043e\\u0431\\u0435\\u0441\\u0435\\u0434\\u043d\\u0438\\u043a\",\"\\u043c\\u0430\\u0442\\u0447\\u0430\",\"\\u043c\\u0435\\u043d\\u044c\\u0448\\u0435\",\"\\u0432\\u043c\\u0435\\u0441\\u0442\\u043e\",\"\\u0432\\u0435\\u0434\\u043e\\u043c\\u0441\\u0442\\u0432\\u0435\",\"\\u0440\\u0435\\u0448\\u0438\\u043b\\u0438\",\"\\u0440\\u0430\\u043d\\u0435\\u043d\\u0438\\u044f\",\"\\u0445\\u043e\\u0442\\u044f\",\"\\u0446\\u0435\\u043d\\u0430\",\"\\u043c\\u0447\\u0441\",\"\\u0440\\u0443\\u043a\\u043e\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u043e\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0439\",\"\\u0440\\u043e\\u0441\\u0442\\u0430\",\"\\u043a\\u0438\\u043c\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0435\\u0442\",\"\\u043c\\u0430\\u0442\\u0447\",\"\\u043f\\u043e\\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u0432\\u0448\\u0438\\u0445\",\"\\u043f\\u0440\\u0435\\u043c\\u044c\\u0435\\u0440-\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\",\"\\u043d\\u0430\\u0448\\u0435\\u0439\",\"\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\",\"new\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0435\",\"\\u0434\\u0432\\u0443\\u043c\\u044f\",\"\\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u0430\",\"\\u043d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u0443\\u0442\\u0432\\u0435\\u0440\\u0436\\u0434\\u0430\\u0435\\u0442\",\"\\u0434\\u043e\\u043d\\u0431\\u0430\\u0441\\u0441\\u0430\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u043d\\u0438\\u043a\\u0438\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0435\\u043d\\u0438\\u044f\"],\"x\":{\"__ndarray__\":\"DAnCvLWRcL/aWuO+8qR7PZI0Ar6HVs2+Ta9Jvw+Th74BPzq+ccuiv5F3H7+PEhS+LJ/RvgjkCb+eN6a+58Nqv9E0Bj9vqSo+Vu2Tvy5sDr9VLLO/XAhqv4ivPL9JUwm/kH1pvyE/k79hBeI/xwPBvWkoJz92it2+frOGPhLKEb+eCEk+s1sYvhqgLb7EPRS/XrEMP/Iqnb19dTu9tgWKPkVacL9ntGa/oKdGv63Hr78kIP69w0Wjv9s+kb89mVy/8f6fvr6iO79OWnS/GLblvB3SoL9KGRK/O/aKv4V5vb/sToe/G9bZvkISYL4CWoC/LIBTP5Wui782FQ+/EwO6Px/euz0dGeE/hMVDPVMo6L/wkcY+3LeIPzRZmj8S2Xi/3B/jPgdHGr9MNyU/pJuAv13t1j/G3Le/EkrDvnbDzj94zkW/T5k8v3Abnj6XnJw+/RZPv2G9Cz+iII2+1lWOP/Lh3z+54VG/AvV/PgDOwr8IRli/wR/ivqpVhT/8Op6/3uSxPnJhiT+etnA+RHTyP+c4CUAk74w/50oJv3OXkD3kdYG/MViiP0k6+z+eSXW/FsCbv19XuT9/Vb2+b/0wv/CgnD990Yg/Qwf9P6Z/gL9zZxdAmOP8vrJqxD/RBiY/YKPHvvR0nT8OECK+KbcnP61OBECACKO+tRjHPjod7j9X2AZAFnSQvzycLD8GvsG9cnSBvzFMhr6oJh6/713gPnOzir+tAjJA5vxNvaa+mT/HbyY/DjaXv+KVsb7gGeu+hH1DP6J4p74GFo0/E+qTP6mus7+8P9y8CgXdPiMUVr9Oc0k9zXOGvhLJPr8H3Uq/bCxdv27l4j13Tik/LwKCP3ZMTr9iwcE94BAov/IiTb8XZts/zd3JP4i2aUA9CGhAubcpPqgJc0CX7Kc+dDMTQGqB9L5r7qG9yW5JP9fugr4i6aa+kyjBvvZzrL8qo4RAJKaPPvAxiD/8OoU/ZdWwOsXET79aZA5A2hyyv22vVb8ktva9sEkLQNVsBL9TSOy9T0w4v9EKAb9DfXtAgmOmP7qGGj9LmF0/zokSvsvrQD8to4A7BoBovwO/w7/USi+/SaSxP8Gvt733M+c/zGURv0aeYr8Qso2+kE+iP69PvL9v4zg/7DZPP6KTrz6tG2e/+chcPiFIrb51F6k/8P9zPwZiRr+WJ74+nSUgP/skqr4aXzM+OpcBQHzyJT/X/t6/D6YFv8aD2z/reau/S1KrvgGno79dRrG/ShqxP1gJZr7sZ3Q/4hs7P/49Dj8QKB4/xxtmvzAEhj+c5I2/o/WLP12ruz4Ig84/yBLCPx+GtjzCkcM/Pug3Phdfgb9BO6o+o7g1P7RqDz9llv2+Oe7Vv4+HNL99xJW+kvKlvrG8Zz9/viu/TD9eP6qjxb4a82O/sL2BPzpwoT+IVhBATt76vgY+uj5GCsO/Z7CaPyNfQj76ZMS9QOnVPyMmlz/zJWK/jgY2v2QjsL7TuoS/09mLvx/QrT/6wwA/6DfLP0kkgD33EI4/z3hhP30ajj9yCtm+iyqiv/ZvIL8IMNw/EI4Cv1/73z/HFak/l+k8v6JC/L7y6sa95PM5P8iVfD9cEkM/a8A9vwynyD6l9Iq+c1B5P/Xduz7IQqA/OTs4v5I9wz670ZI/Vh5gvsg55L5DsJU/6hTFPrfzk76X9a8+8rMsv3EJubxjVYQ//bfqvehMwj++tOU/f0TSP7gp3D60Jyy/XJfDPy/iOD4L7y8/bY3eP6L9I7/FeIS/u0skv6froL+XJk69+D+xv39EGr9H6ey+LMAGwEEGtr6MYbc/ASiRv8+yr79V+/i/N0exv6lzuD48FGM+J4FpvmLN8L7gQcM9ldu2Prp3eb+Twog/U6BWvqsFgb3mT5q+XmazPxbvU780ZrK/HkCBP5pSv70kfN6+Nl/yPn1ua7/b7dg/IMJmvxw3Kr+JCa++4Azivmx9+z5odrM/ptSMPvlcX792J+G/bf2Gv/i4qb7T77u/Wk2cvj+vH71ta0k/R1yYPvzpIT943YS+1JB2v4U4rT0Vx62+Jb2Qv3AqSj4/HRW/n9pYP9p09T6SWh0/8wTfPwtDPL6ETay9WcSAv2aIFz9h7Uw+BQosv3GTbr/INas9GdvcPTaAq7+e+7Q/Zy/+PlS5er9Futs/ytXtO/IlVD+Prj2/WYEZPGQJkL5Z6KM/pUIHP82poL+Gz04/FDEcP1cG6D9JycM/1bfWvsjcYr7PphM//WL4vWfLiL7X7b++4d64v8pDkL+OgQI/Qkl9vWT5ZD/1IjdAGxngvtqogT9vHI+/TVCyPx7ZqT9rGWxALQ9zPqZjyT2anWu/M1NaPWM4pz1OST2/qsgFv3/nXL8YXsg/Sn4aPpcTRr7jq3BAFwWNP+WWYUBTR6a+k6WgvzGQ9T+msc4/Cb6YP/ANDj233qG/q4KmvsWgEj5MEQ5Ahc20vgoTKb8EQ6i/hWc/v9foGD4VjZW+wh/qv+hFpb++bJE+yPCQv+v9j74Tjrq+NWUrPzeDE79w0ks/8Ej4vsYBYD9dK46/Yd4SQBBArb5lRVo9aq9Hv4/JYb+7gje/KcIxvz+I/r4KAqq+1bnjvum2hr+SNXE9ezr5P0COkb8ftjVAi8kxPz79q7+lWZI/xeenvoWu3j+XmY2/Z60Qv72mzz7NvBI/oHKgP63rRj5+l1G/MaKVP98a+L6jHwE/e9mzvUSsOD9Adh2/l5lhP+Zxmb+Kiny/wNrcv2nFZD8tw+W+5hgAQBj6J755jMm9KdoAP0i3mL8o5LC/HtjWPqsqdL9TyNq/TIWWvsqTtD+BsLM9BzJ3O2BnsD965CU/Xrdqv/1Fnr/1lcC/KG7LP+A8Kr9R9yM+BoUDv2fo4D6OS3U/G2QlP8p2TL+yHYK/msnDvqjhDL9D3sa/WYbavhn8KT93PYg/vyTZPtZ72b/pKZG9nctcQGtZSD4zVce+CV8LPi+VOr9xCMQ/+XdaPk83UT/G4sq/DPUbv1SQ2T7wiha/iVSpP8MIiL+P986+Yd2fvzNvGr4GBe+9BDqQP4lkvD1basy+SZNFQJsCsz2+cS6/dKu9v6r8QL8gJCq/r5+avgRfOr+lhYC/SobnPLdbk77V3DW/kWBCv1euAb/lQdO/M1ydPob0lj+zX0y+ZARJvltCDL+0E4W/mTFov/NcFb+c4sy9TUgTvxnVl76xprq+hcmEvn4DJ7/SHce/DbHEv/X3Lb+2GzG/58lCPwjWZ79y+yu9qgksv6j9or93lHs+wScQQBr6VL/jmzBAZW9sv7F1hL4TxtK/pngAv0iFlT8XBeY+1KTwPurdAj9L3Nc+qatEP5B6fL8Mnz8+LhUsv9UI/z1+TX4/8wW2P68MZL+hWMC+SbiSvnQXQD+WbrS/EYzAP6da2r6wJ48+byhSPqwOtj+vomK+lVopv90OQz+r7Wu+LTDEvqp/WD9zogq/vcMGvzZKVj+tsRU/TN0dv7Lxvz9LOpU+XBZ+v5fPrr9yLkW+NPPMPe8Lmr7whFC+x+KCP/tCLT+Buhi/uEqpP0GztT7xQqW/soYEv3ZTYr8gJLO+C4aev745DUA2HB6/l+JFvyJ/rD/8Mpq/WuhCPgjv5r6Qzam+KH6evtLFuD4Kd7i9Ob6Xv/kTBL6h5+m+HSvCP2LqUj3xDE6/sfGwP2Kqwr0AfpK/G/kGQA7Unb8OYLq/6EMTv+Vw9b7CWCO+OLQJv6h5Dr8OzoE+zd4cvoXjHUDRvyu/HJeEP/g3mz/zRMc+iwsJv4ORBDshMYI8LAX2PvY4FLkwq2C+geKmvjUTGL/Hhka/xtPDP97xsD5a4P8/87phvzfePr51nAe+aOZAv/Ez5b/R9Jq/hr9nvxbdTj7rlkU//QSDv/tdmj4mNLy/s9OyvwqnPL9JTke9C0bTP/buyz6MP5Y8wKWovmEzcD8p0OW/FR5FQGZ2Xr8fTVO/10gaPr8fLD5gUghAYtdsv0zLo78xp0ZA/T5FvzW5Ir656p4+Sr8Sv5ZhAD+Mehm/dKI6PoPwez5R8IM/BfKvPBqmZL8tWMS+IWzmPhwdNb2w7tg+Y0cNP0AODj8o550+3wQtv6Ju8LzSW7G941reP0sJCT5x5co+J/5Pv6nZgT/xhz4+ISo8vnjpS79axec+LYhIv5rHXj7c0Ee/jlxkvb7Xqj4WuCO+zr5av2szPz+JJIu/KwjNPRxS5j6jmOK/V7b6PjCl/79Xi90/3U7Jvr24jTzQZAq+Bwafvy2fJT/aeHM9WkCvvrwdfj+AhI++It5Nv2qIeD6BDGa/XPoHv/JFKL+1+S08U+dhvQyj+r5oYhQ+ilv6vps27z6pKTw/QkdlvfPfCL/pqBu/8Ekuv0kaLb/H2AI/q0/lvVQ0JT83m8K+oeLbP/+xe79fOaO/HpiLv+pkeL/xMdG/lVhOP/3h174S2JW+KOjLPg6CJT/n1wW/jeyhPxM+gb+czBW/IlJ2v2yajr9xb/+/aeotuc7cAUBnvgC/Vq4OP3aQRr5+XBI/d66qvmQHKL/uVgk/5Z/Jv86xob5CtEe/7HSuvw47tbwL9qg/pBEpP7cf2T7+KKw+zeGpvghzmb/rJN6+55puvyXEbL9VVdO/tKcHv40nMD6mRWi/T98Tv2ebub/WceC/WxAYPnqBgz6PPJm+5BdWPuM0WLx86Mq+EIkZv/KFnr+Pxqs+IT5wv+jTOL9tDiM/SoWOPwYOP78vCq0/1+u+uwscWr/Ugog+qA1GvnyWxL7wbBO/m/44P649Ez8VCe+9/FuyPtcFmz/8moM/mjxYv4sjJ70PuVW/xWiPvZgsdj9eV8Q+G8mzv8MXcz9pW3u9d+O4vkw7qr3TIKm/+tpNP4WHRD+QN9A+v/Q7PfjXa7/Nlb4+luACPkU8jL7vleu9fYGKvm3QAEAE3Ly9tOL6PvDJtb4LGw4/tkYJP+j/sL68JSI/lpl4PptLcj+bnD2+kqEmP91x9T6/BE2/OGDfv5vnjr+7+Ck/rZSHv9sxKj9awGU+6w1Nv/zwOD4Xqww+/DzpvRpXIL5K/dg+iqGrv6kS7b7A4xc/U+1WP80fRb+kpBU/KpTXvmlTnj9sI8q/nQwHv+tGe78T/8e/2NPAvrqArb3Kz46/eTXwPyRfA7/P2f2+DN4Mv3nn/T6Vyp2/fInWvvKTlz1IS5o+ft9gP80avz1OkXK/XFcbv2IQcj8BCMS/RLq2vtyonb9+Pn6+HglePwQu9L0g1AI/zMNSv4K3dL45g+++QBKnP6E9Bb/vdQVAZOCBv1+uAb+I3oO/6mEBQHDIN7/pYx+++uGIvzYYGj/H2G2+F3jJvkZX3779hlq/aCUzvw==\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"30WovW73mD57pk++DokwP5FaRT+/vhM/Yfslvv4hLLyv2Hg+o/oBPvJDtL6nx7w9kXpnP0TpZT+z72o9nRjtviEBY7+hj2k/rEf3u4Z6bD5X3GY+2oI5vmWYPD55AkS+CiurvVmboD7Iygc/EfvJv4W+jb8UnSq/TFwwP6h5Xb7f8mO9VjK+vkR+T76kFk4+xLbXP3ac2T6s6No+JradvwfNJz3mX9Y+wIqxvneprL1xvXg+GoqWvspyB7+r60u/KzUkwBPkuL9s80O/M16RPqw4jb5J+QG/h6XPPYNZXL76ES8+n5RgPhJTpL+Dixm+aDP2v2mcjL4rONa/x7LFvzHzxj+QFCa/zly0vyYXEzwl3Na/NDG5P+/dZD+5hwa/oxqsP1sN+r4br/0/5Q0xPf2df78wSne+b+1SPy0ckT+UVh8+pvqQv+9NzD76dtW+Q47YvSQ87D9gFe6/PoPXP3uzg796Ht6+X3IZPxyjzb1QCSG/W972vWnK2j/Qpci+MTWKvwXytL8OaQbAszXgv/Df7L/TwwPA7sHLvxaN5b8z+A2/nlvzv5GNpj9nquQ+P32DvlVNrT/AaqS/ZprePqfxkD6ETZy/9Vi1PRtj2L5j9zu8Wi98vtVBh7/hLoS/A+TovtwO679ayLU/6SEnv5D20T9DW3A+6nVsvgA0MD8kse6/6BaiPTOzzb9MYfi/UNKNPxE7u79kQMc+80NFv1AXGr5Fx3c/4gyQPgpHNj6Lggw/7I0Qv06xtL9/V3++wyQNv8X8478orYe/fHvSPhTkZTwL6vM+NEQrP61at7/YJdA/OOefv0oDP77ExDO/Rs+Uv1NI/Tw8Huq/tPdsP9rNib8Bp4Y/WHBsPyACBL75HgxAr5MjwAkQsb7htky/3hiXvnlArb5ituA/WtZ6P2TcJz+dGR6/j62vv0neoL615AU/tZAfP+GhKj5Bs5W+xo9GPR91dj48Jqu+9mxJvTPqPb5Dhuk/rXSfv+lDkb/097c/5MTrv4ewXz/529q+KpYBvou02z1sxCu/DQ8GwFOsA8DNqNq/bV4/PcNO3r+48SE/sfoOv3Nkv7tDbKI+zzb5vxZ8oj+vpMm/67Bvvnq9nz6Q8H4/AZmWv1ReZD6pt9g/QO6DP9lbiT/eiHc+wu6XP8M3+T2RmLQ/cUePv4J/5z6L9dM/O1kTQGnacL4icwg/sH4MwEEjtb85iuy9qSW7PrVvu78AQwy+0E8APteSAj4t+/K+H2zOPzK+wz2+bJO/QX9FPnQxfD+7Hte/MGg3vkIXnr+uQmw+mDS8v1ChuD5CLJS/vvqWvzDQGb9ET8W/v1mNPmt/H7/pH4s+WuneP3re9T8hD4w9OrAyvaSA7DwJV0k/WzUEvrEyUD4aIb++tcFAP0CsfD9pGgc/Q8qGv/MHyr/0a9s/3L2hP1epTj/iBrg9zfrMv2ieLT/Jus++PHH6vr+UWr/CHom7Sp7FP/jcy74YC4G/icMaP/H2Q7+Yj4g/gOG2vyfDoj75zGS/C1M8P0Bu0L9rVPq/tWKqvuNopr9P4IO/YXUqPcwANT9Vie0/bZbyvuXIIL8yxjY+3Y7xv7W5qT6XLLg/yoUav17PUz8KtYe+mojxv1dyR7/Z0Zo/BJeuvtJKNL+azPU+sFHHv7nIIL/twuQ/+NOSPjAyRL/CzNg/V8Q7v80irj2hc/A+FAkZPxVDnj/R05I/LMZ1v5tBjj/13gM/B/dxvwp+DT6mB8c/28qPv9qzTb/ZKLA+eTbqvtNqZT7m2Q7A+4JJPqEQmj7alr+/Kcgcv6OnFT8oYqU/NYcEveNUHT/uwEs+xTYkP138Cz+ia9e9xpfZv5TetT8fyvy/Vm6jPxf/gj/LYuG/Tg2+v62OJr9O14a/6jBJP1lynj/9h8I9ew3dP1DUT7zevJE/Rj0bQJQUQz/warM+ETRKvn2wnT7iby89mWjAPmbk/j8sOqM/YjOxv0pHgz0iMvC+Dgz7vto8nT6UCHu+Kkm2v8qf9L/hqWE/d3nPPoTKIj+VYVW+b9aHvO7Iiz9ZcaK9m3iXviMXN7xjOYu/q1q8PzoYaD8MYhk/vXkDv0YJS78o+kE/FQSAPwwk0z/BvSm8fjrYvyUI9j1K23Q+iJhuP3s5sD734ca/cqKEP8Qg3D2Drae/j900P5ZV5T7cMMy/ShJhv786OT5Ndvc/JAxoP89+jL7TM6Y/79paPuqhw7/0T7C/003UvnaPB7+6vtY/uppgP9ECDb+YYmy/tlcevk/jwr5M70E/1U/PPmBMkD9MqRc/LsZyP1phgb+Ie3w+cDt2v1CFBj/K5Is+mrZNP6Imlz8nHbQ/8s68P9imgz6FbYq/zAneP5F1Qr+xeXa/lCEvwDS3yj7bltQ/q2QwvhGll798BQ7AOi3yPUFLb79Bj4s/xhg9P+GyfT63SrC+/jQiP57tij8x4E6/6jjSPqvyqz5lzz4/lUXQv8Rlcj8s9xA/3/bNPo7wjz6Zud8/4g8Rv0d+AcBQHRs/DS4yP6RmKr6Ppeo/OygGvvSwFz+C620/nUyoPjjRF75BP30/21ZIvxayur7lSis/gQdIP9l+RT9UhdK9RqCHP75GmL17H6Q+sFFoPu8RWb7FqoI/c/iHP5NPq70vape+plf/v92O3r/oCha/vUD3Pecbij+25GQ/cZq/PpE7KT+HJ3A+od+HvydZrT6vppC+HA24P4Hr4j+Iabe/hq8iP8auBr9AT7I+BOPQvt9Yiz9EJAI/Fg3qP/sdmr80rJe/tJIsv+tfXr9ZiZA+c//hPtJWjz6/hBQ+ZYcgP7ro/z/cJK0//kQMP4jbwL978Ma+nWCmP4KLJr9vC0M/pYbeP/XObD/G/uw9+3WNPr/ozD6zcEs+8wtbP0KApb2k0Ps+3LDMvp/HAj9URyO/FIAgP+SNp74Ss5C/gxsYwA8Wvz3I7Kc/rCzUv/S4EMBN4L2+YvPhvuPBlr76cqG/dV62P9Mvrj6SXy8/k3nzvrbPOT87x+W+pAJwv85IL75R0bG/bQyXPqA/sj7oe/Y/IPWtv3ZMfb8BUgvACAJJP//FcT892EM/5XMiv21hh7+irYg/gYi5P9Oasb+cYb4+O46FPlAQBsDRIZu+sLAHP68J9j6GuD8/Lavsv+0zS75QjRY/Z0SeP1Ihsj6xPpI+jXlsvo3S4r9lE5I+sAgXPw3juD/LtCQ/ro0ZP2S1Wz+2kFQ/5oaUvoYP9rwIlK0/WPKuvvdcv776gIO+gbyWPgpArz4J1tA/yseWv+iqPL6J+b8/vzEYv94NLz58Mvw+8MSzP83eHEDjVHE//yzPP8PIGb+E4F8/MksmvylPhL91H4A/RxuBv0DsdT8terS/nkvBvavAnDy+zQI+cZ3hvjYwrz6IVJu+1oA8P4GGFj9jf3g/q/QGQB4Vej30ewO/oWhCP0tTwr4YEyE+usqJPkW5Ur83gUG/bNYCP+yCKb+6LLo/JTLZvqddaL/20Y+/3Ox+P2cAtj/1A6A/j2gnvi/zQL+s9h6/rZVIvzoD7759fVI/dWFQP5w6ID8QpCa8C6j+vtGRPj+L2dm/atYAv7XOqL8LsdO/626uvQYpC0AUg2Q+IRVvv/BQJ70/LZe/j+Zfv/dfaz9kge4/R8vSPWT/WT/LshI/+U7UP0/JO7+xwo8/XXK/PHR5Zr53YyE/sJUyPdqJkb3wv/0+suSFvXx9lz/rvge/Mrupvgfrg78mrKs/Eh54v4WCrD/s3F4911wHPuM6rb+64hrADGpvv4ngy72peR7AEHWrPZgWor/Rj/U/7bSXvopGiD0Lfls/MCM2vYroDkDpmJy/iVAGvnOshL+WvmY/2IN6vLkZCr8XXnQ9Fx+5vrFxRz+9vtQ/QtwLPoWFd77epiK/dtxeP4vhNb9sBA/A2bgKwD+aEsDX070+UsY0P3zLU7+Jtn4+vj42PlEgjz0mRyc/gC+vvesaOr/mGgjAnnENP/HMHT4EUt8/OY32vgSt1b+QtoW/S1ruPydthr+XLpk/xKPbP62Nh79UIZg/IiYoPwNCm7+Cv/m+YjmOvjjI0L5vM5k/eBSZPnAoHr+H6pA+bykWv46iZ7+eyxw/z+tlv351vz92ooE/A5ptPp8KvT9Qj4E/0/Lqv5uZwL6rQiC/QAxEPogymD9DFXi9slUTwMVvvb9cVZw+hXF2PppVm7/etAu9ahoVvl0b+L7yW94+3XAywKJvX7uhCZK/xQa4vmVVFr6S7QM+oHy1vvJFeD+V+Bg9I86RvwzyOT41BqM/3vCdu4OqGD/Fsjo+Qz94vzTKk766frG/0jbSP4rJPb+/uZE/U2iYvuN5RT/3CxhAXmJEvlRsWL0qGSG/KR8pP05ltb+SXQi/RJmLv7YkWT+HnTk/aYTQP2udj75OIGA/X3zxvKE97j21+YA8Nx+pP+ZGQb5xOU6+LuwXwCEFFD8rSbm/Zg8SP6TrfT8KVaA+McdYv25IOj8FbEC+uMKTPxRUGD4NDYm+Si/Uvkp4VDxZ6pq/+vbQPwBi1z4zC1m+q+K6vlqSLT5EAsA+8gIBPwljwD8w5JI/V9YSQBgvnj7uIgs/n9xOv51FPj/e71Y+sLWev90XlL9xjkK8Gw5UvxBGsL7Z9/W/cgoPPmuQWj+0+oG+Fbk6P3K4kL9We6i/v7Y+v/8gqj+iZxnARkExv2/T8j0C5TO/k7AgPalXjz6lNUO+F/7IPr1TFD9BBxi+CThyOVHNmL63Crm+8++yP26d8r5yfWe/4isEQOFVx7/U1pY/e5zGvnWmtL9Zyn0/Pg4ovqcSOb9btfU+MDJBP/vy5T+0Aj0/exDQvSkSj78Sqvk/zbIxPr4J5b0CATY/rsPQPyHpQj5NxJI/tH4tvkUkF7/kSH2/gCy2PmCStj839UQ/xDSWv7NSQD8HzFq/6q4qPnWfgj6vL+y+5ASbvht0XT+G2j9AEQxUv4y7mz+dUb4+JUekv3ZAar+hKg+/e+UcPkrtm791Fre+VCnnPfcj0D8meeQ/D6dOPz3Lw7/pBd4/UXNHP2UnEb/fTE8+k5bBPs4vEz/R6yE+JyaEP9Q4Gr4ly7A/Z46CPhcYgL8ZaAVAklhyP4STM72IkI+9q64PPwdpeT8hWoU+tQndv8w7Cr5AqwrAyn00P2lSXr93r7U+DNngvpDqrTzI96W+4TXrP8Dh+b5mhN+/oKaEPeO/Bj/3vhg/biS4v3YhQr7FJJi/rxg9PyeptD+1ao4+xziMPqQjkD8YURS/ND6jPu31Tr/sKzo+H4tEP6zUlr7HEmM/vruxPfxS/7xozdK+arvnPnM0Sz16okY/OSF4P7YIUD8sDBc8H80sPw==\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1162\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1161\",\"type\":\"UnionRenderers\"}},\"id\":\"1106\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1144\",\"type\":\"HoverTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1127\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1126\",\"type\":\"PanTool\"},{\"id\":\"1127\",\"type\":\"WheelZoomTool\"},{\"id\":\"1128\",\"type\":\"BoxZoomTool\"},{\"id\":\"1129\",\"type\":\"SaveTool\"},{\"id\":\"1130\",\"type\":\"ResetTool\"},{\"id\":\"1131\",\"type\":\"HelpTool\"},{\"id\":\"1144\",\"type\":\"HoverTool\"}]},\"id\":\"1132\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1122\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1140\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1141\",\"type\":\"Scatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1106\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1140\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1141\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1143\",\"type\":\"CDSView\"}},\"id\":\"1142\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1155\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"1163\",\"type\":\"BoxAnnotation\"}},\"id\":\"1128\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"1106\",\"type\":\"ColumnDataSource\"}},\"id\":\"1143\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1126\",\"type\":\"PanTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1159\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1117\",\"type\":\"BasicTicker\"}},\"id\":\"1116\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1159\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"ticker\":{\"id\":\"1117\",\"type\":\"BasicTicker\"}},\"id\":\"1120\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1129\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1127\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1110\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"1107\"]},\"title\":\"Bokeh Application\",\"version\":\"1.3.4\"}};\n",
       "  var render_items = [{\"docid\":\"4c68842d-8555-4d95-9546-52df0096bf37\",\"roots\":{\"1107\":\"6149569e-2d8d-4eb0-a15b-0ba828cbe299\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1107"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    output_notebook()\n",
    "    \n",
    "    if isinstance(color, str): \n",
    "        color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: \n",
    "        pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_tsne_projection(word_vectors):\n",
    "    tsne = TSNE(n_components=2, verbose=100, n_iter=500)\n",
    "    return scale(tsne.fit_transform(word_vectors))\n",
    "\n",
    "def get_pca_projection(word_vectors):\n",
    "    pca = PCA(n_components=2)\n",
    "    return scale(pca.fit_transform(word_vectors))\n",
    "    \n",
    "    \n",
    "def visualize_embeddings(embeddings, vocabulary, word_count, method=\"pca\"):\n",
    "    word_vectors = embeddings[1: word_count + 1]\n",
    "    words = vocabulary.index2word[1: word_count + 1]\n",
    "    get_projection = get_pca_projection if method == \"pca\" else get_tsne_projection\n",
    "    projections = get_projection(word_vectors)\n",
    "    draw_vectors(projections[:, 0], projections[:, 1], color='green', token=words)\n",
    "    \n",
    "    \n",
    "visualize_embeddings(embeddings, vocabulary, 1000, method=\"pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNicpGCnpcZd"
   },
   "source": [
    "### Задание 1: Рубрикация: самописный word2vec\n",
    "\n",
    "Проверьте, как модель выше работает в задаче рубрикации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:17:42.668041Z",
     "start_time": "2020-04-12T18:17:42.662056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4871542 ,  0.00996983, -0.4114669 ,  1.5288379 , -0.4958942 ,\n",
       "       -0.9334554 ,  0.45812514, -0.15939265,  0.29071546,  0.33591405,\n",
       "       -0.3964914 , -0.448543  ,  0.0661929 ,  0.25176588,  0.73372465,\n",
       "        0.25915122, -0.6093377 , -0.24376357,  0.30421245,  2.2538934 ,\n",
       "       -0.15664686,  0.32170027, -0.31348467,  0.57391906,  0.3352386 ,\n",
       "       -0.08488153, -0.84000367, -0.4573204 , -0.33783725, -0.1849112 ,\n",
       "        0.15400788,  0.11144926], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "import numpy as np\n",
    "\n",
    "def get_text_embedding(model, vocabulary, phrase):\n",
    "    emb = model.embeddings.weight.cpu().data.numpy()\n",
    "    \n",
    "    embeddings = np.array([emb[vocabulary.get_index(word.text.lower())]\n",
    "                           for word in tokenize(phrase)])\n",
    "    return np.mean(embeddings, axis=0)\n",
    "    \n",
    "get_text_embedding(model_skipgram, vocabulary, \"Исландия рядом\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:19:34.153971Z",
     "start_time": "2020-04-12T18:17:49.911684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Интернет и СМИ', 'Спорт', 'Мир', 'Бывший СССР', 'Из жизни', 'Культура', 'Экономика', 'Ценности', 'Силовые структуры', 'Россия', 'Дом', 'Наука и техника']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "step 5000\n",
      "step 10000\n",
      "step 15000\n",
      "step 20000\n",
      "step 25000\n",
      "step 30000\n",
      "step 35000\n",
      "step 40000\n",
      "step 45000\n",
      "step 50000\n",
      "step 55000\n",
      "step 60000\n",
      "(63356, 32)\n",
      "(63356,)\n",
      "step 0\n",
      "step 5000\n",
      "step 10000\n",
      "step 15000\n",
      "step 20000\n",
      "step 25000\n",
      "step 30000\n",
      "(30159, 32)\n",
      "(30159,)\n"
     ]
    }
   ],
   "source": [
    "target_labels = set(train_dataset[\"topic\"].dropna().tolist())\n",
    "target_labels -= {\"69-я параллель\", \"Крым\", \"Культпросвет \", \"Оружие\", \"Бизнес\", \"Путешествия\"}\n",
    "target_labels = list(target_labels)\n",
    "print(target_labels)\n",
    "\n",
    "pattern = r'(\\b{}\\b)'.format('|'.join(target_labels))\n",
    "\n",
    "train_with_topics = train_dataset[train_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "test_with_topics = test_dataset[test_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "emb_size = 32\n",
    "\n",
    "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_train = np.zeros((train_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(train_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "        print(\"step {}\".format(i))\n",
    "    X_train[i, :] = get_text_embedding(model_skipgram, vocabulary, phrase)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_test = np.zeros((test_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(test_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "         print(\"step {}\".format(i))\n",
    "    X_test[i, :] = get_text_embedding(model_skipgram, vocabulary, phrase)\n",
    "    \n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:20:47.672456Z",
     "start_time": "2020-04-12T18:19:34.154941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      2447\n",
      "           1       0.92      0.93      0.92      3429\n",
      "           2       0.73      0.77      0.75      4291\n",
      "           3       0.74      0.56      0.64      2156\n",
      "           4       0.70      0.75      0.72      2191\n",
      "           5       0.76      0.68      0.72      1995\n",
      "           6       0.82      0.72      0.77      3185\n",
      "           7       0.88      0.66      0.75      1177\n",
      "           8       0.50      0.64      0.56      1663\n",
      "           9       0.62      0.70      0.66      4324\n",
      "          10       0.74      0.68      0.71      1182\n",
      "          11       0.83      0.77      0.80      2119\n",
      "\n",
      "    accuracy                           0.73     30159\n",
      "   macro avg       0.74      0.71      0.72     30159\n",
      "weighted avg       0.74      0.73      0.73     30159\n",
      "\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEnfVqVYpxgR"
   },
   "source": [
    "### Задание 2: Самописный CBoW\n",
    "\n",
    "Сделайте аналогичную модель, но в архитектуре CBoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:20:47.677470Z",
     "start_time": "2020-04-12T18:20:47.673453Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import time\n",
    "\n",
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings.forward(inputs)\n",
    "        output = self.out_layer.forward(projections)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:20:52.469376Z",
     "start_time": "2020-04-12T18:20:47.678466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 1963,    11,    48, 68719,  2875,     1,  8387,  3056,   636,    46,\n",
      "        77084, 14861,    31,     2,     1, 11475, 20072, 20115,   394,     2,\n",
      "            7, 27271,  6182,   794, 33554,     1,    29,   303, 60647, 73081,\n",
      "        63443,     5,     1,  2390,  1030,   388,   163,  5425,  1855,   641,\n",
      "        17051, 10684,    38,   186,   878,  5182, 41708, 26945,   405,   102,\n",
      "          454,    83,  3843,  6469, 22230,  5889,  1793,   789,    54, 53768,\n",
      "         1232,     0,   232,  2384], device='cuda:0'), tensor([29343, 29343, 29343, 29343,   352,   352,   352,   352,   994,   994,\n",
      "          994,   994,  5853,  5853,  5853,  5853,     0,     0,     0,     0,\n",
      "           56,    56,    56,    56,  1764,  1764,  1764,  1764,     2,     2,\n",
      "            2,     2,  2516,  2516,  2516,  2516,     3,     3,     3,     3,\n",
      "        11438, 11438, 11438, 11438,    41,    41,    41,    41,   833,   833,\n",
      "          833,   833,     2,     2,     2,     2,   394,   394,   394,   394,\n",
      "            1,     1,     1,     1], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_next_batch(contexts, window_size, batch_size, epochs_count):\n",
    "    assert batch_size % (window_size * 2) == 0\n",
    "    central_words, contexts = zip(*contexts)\n",
    "    batch_size //= (window_size * 2)\n",
    "    \n",
    "    for epoch in range(epochs_count):\n",
    "        indices = np.arange(len(contexts))\n",
    "        np.random.shuffle(indices)\n",
    "        batch_begin = 0\n",
    "        while batch_begin < len(contexts):\n",
    "            batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
    "            batch_contexts, batch_centrals = [], []\n",
    "            for data_ind in batch_indices:\n",
    "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
    "                batch_contexts.extend(context)\n",
    "                batch_centrals.extend([central_word] * len(context))\n",
    "                \n",
    "            batch_begin += batch_size\n",
    "            yield torch.cuda.LongTensor(batch_contexts), torch.cuda.LongTensor(batch_centrals)\n",
    "\n",
    "print(next(get_next_batch(contexts, window_size=2, batch_size=64, epochs_count=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 7285460\n",
      "Step = 1000, Avg Loss = 8.0443, Time = 10.11s\n",
      "Step = 2000, Avg Loss = 8.0811, Time = 9.85s\n",
      "Step = 3000, Avg Loss = 8.0571, Time = 9.85s\n",
      "Step = 4000, Avg Loss = 8.0354, Time = 9.85s\n",
      "Step = 5000, Avg Loss = 7.9966, Time = 9.82s\n",
      "Step = 6000, Avg Loss = 7.9848, Time = 9.91s\n",
      "Step = 7000, Avg Loss = 7.9513, Time = 9.96s\n",
      "Step = 1000, Avg Loss = 13.8264, Time = 18.24s\n",
      "Step = 2000, Avg Loss = 7.4821, Time = 9.98s\n",
      "Step = 3000, Avg Loss = 7.5237, Time = 10.04s\n",
      "Step = 4000, Avg Loss = 7.5439, Time = 10.04s\n",
      "Step = 5000, Avg Loss = 7.5741, Time = 9.86s\n",
      "Step = 6000, Avg Loss = 7.5786, Time = 9.95s\n",
      "Step = 7000, Avg Loss = 7.5857, Time = 9.90s\n"
     ]
    }
   ],
   "source": [
    "def train_model_cbow(model, contexts, batch_size = 256, epochs_count=10, save_path=\"model.pt\",\n",
    "                loss_every_nsteps=1000, lr=0.01, device_name=\"cuda\"):\n",
    "    \n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim \n",
    "    import time\n",
    "    \n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    # устройство\n",
    "    device = torch.device(device_name)\n",
    "    # перенос модели на устройство\n",
    "    model = model.to(device)\n",
    "    # инициализация общих потерь\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    # выбор оптимизатора\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # выбор функции потерь\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "    \n",
    "    for step, (batch_contexts, batch_centrals) in enumerate(get_next_batch(contexts, window_size=2, batch_size=batch_size, epochs_count=epochs_count)):\n",
    "        logits = model(batch_contexts) # Прямой проход\n",
    "        loss = loss_function(logits, batch_centrals) # Подсчёт ошибки\n",
    "        loss.backward() # Подсчёт градиентов dL/dw\n",
    "        optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "        optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if step != 0 and step % loss_every_nsteps == 0:\n",
    "            print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "model_cbow = CBOWModel(vocabulary.size, 32)\n",
    "train_model_cbow(model_cbow, contexts, batch_size = 256, epochs_count=6, save_path=\"cbow_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:31:30.518721Z",
     "start_time": "2020-04-12T18:31:30.445695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow = CBOWModel(vocabulary.size, 32)\n",
    "model_cbow.load_state_dict(torch.load('cbow_v2.pt')) # текущая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:31:32.226569Z",
     "start_time": "2020-04-12T18:31:32.197967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['путин',\n",
       " 'городецкий',\n",
       " 'президент',\n",
       " 'мединский',\n",
       " 'брынзак',\n",
       " 'нечаев',\n",
       " 'медведев',\n",
       " 'шаманов',\n",
       " 'сафронов',\n",
       " 'осаковский']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def most_similar(embeddings, vocabulary, word):\n",
    "    word_emb = embeddings[vocabulary.get_index(word)]\n",
    "    \n",
    "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
    "    top10 = np.argsort(similarities)[-10:]\n",
    "    \n",
    "    return [vocabulary.get_word(index) for index in reversed(top10)]\n",
    "\n",
    "embeddings = model_cbow.embeddings.weight.cpu().data.numpy()\n",
    "most_similar(embeddings, vocabulary, 'путин')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:31:38.084378Z",
     "start_time": "2020-04-12T18:31:38.079391Z"
    }
   },
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "import numpy as np\n",
    "\n",
    "def get_text_embedding(model, vocabulary, phrase):\n",
    "    emb = model.embeddings.weight.cpu().data.numpy()\n",
    "    \n",
    "    embeddings = np.array([emb[vocabulary.get_index(word.text.lower())]\n",
    "                           for word in tokenize(phrase)])\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:33:29.233213Z",
     "start_time": "2020-04-12T18:31:43.871164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Интернет и СМИ', 'Спорт', 'Мир', 'Бывший СССР', 'Из жизни', 'Культура', 'Экономика', 'Ценности', 'Силовые структуры', 'Россия', 'Дом', 'Наука и техника']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "step 5000\n",
      "step 10000\n",
      "step 15000\n",
      "step 20000\n",
      "step 25000\n",
      "step 30000\n",
      "step 35000\n",
      "step 40000\n",
      "step 45000\n",
      "step 50000\n",
      "step 55000\n",
      "step 60000\n",
      "(63356, 32)\n",
      "(63356,)\n",
      "step 0\n",
      "step 5000\n",
      "step 10000\n",
      "step 15000\n",
      "step 20000\n",
      "step 25000\n",
      "step 30000\n",
      "(30159, 32)\n",
      "(30159,)\n"
     ]
    }
   ],
   "source": [
    "target_labels = set(train_dataset[\"topic\"].dropna().tolist())\n",
    "target_labels -= {\"69-я параллель\", \"Крым\", \"Культпросвет \", \"Оружие\", \"Бизнес\", \"Путешествия\"}\n",
    "target_labels = list(target_labels)\n",
    "print(target_labels)\n",
    "\n",
    "pattern = r'(\\b{}\\b)'.format('|'.join(target_labels))\n",
    "\n",
    "train_with_topics = train_dataset[train_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "test_with_topics = test_dataset[test_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "emb_size = 32\n",
    "\n",
    "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_train = np.zeros((train_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(train_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "        print(\"step {}\".format(i))\n",
    "    X_train[i, :] = get_text_embedding(model_cbow, vocabulary, phrase)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_test = np.zeros((test_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(test_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "         print(\"step {}\".format(i))\n",
    "    X_test[i, :] = get_text_embedding(model_cbow, vocabulary, phrase)\n",
    "    \n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T18:34:40.354637Z",
     "start_time": "2020-04-12T18:33:29.234191Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      2447\n",
      "           1       0.90      0.94      0.92      3429\n",
      "           2       0.71      0.80      0.75      4291\n",
      "           3       0.71      0.62      0.66      2156\n",
      "           4       0.73      0.71      0.72      2191\n",
      "           5       0.74      0.72      0.73      1995\n",
      "           6       0.81      0.73      0.77      3185\n",
      "           7       0.85      0.67      0.75      1177\n",
      "           8       0.46      0.64      0.54      1663\n",
      "           9       0.63      0.67      0.65      4324\n",
      "          10       0.80      0.66      0.72      1182\n",
      "          11       0.84      0.68      0.75      2119\n",
      "\n",
      "    accuracy                           0.73     30159\n",
      "   macro avg       0.74      0.71      0.72     30159\n",
      "weighted avg       0.73      0.73      0.73     30159\n",
      "\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdtVIUBHp6Qu"
   },
   "source": [
    "### Задание 3*: Negative Sampling\n",
    "\n",
    "Реализуйте negative sampling вместо полного softmax'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:01:21.372742Z",
     "start_time": "2020-04-12T22:01:15.018624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   37,  9006,   256,    10,   157, 30282, 60515,     3,     6,  1401,\n",
      "          471,    30,  2062,     1,    68,  3267,    82,   271,  7098,     4,\n",
      "          118,     7,  3559,     3,   154, 16154,  5778,  3416,  1472,  1380,\n",
      "          503,     7,    10, 15746,    76,     2,   476,     4,   224,     7,\n",
      "         1162,   440,  4898,   394,  2631, 21458,     1, 14000,  2947,  4100,\n",
      "        82113,     5, 10898,     0,  9093,  3689,     1,  6279,    52,    74,\n",
      "         1102,   112,  4133,     1], device='cuda:0'), tensor([    6,     6,     6,     6, 62396, 62396, 62396, 62396, 23698, 23698,\n",
      "        23698, 23698,   501,   501,   501,   501,   226,   226,   226,   226,\n",
      "        11695, 11695, 11695, 11695,     1,     1,     1,     1, 30667, 30667,\n",
      "        30667, 30667,     5,     5,     5,     5,     1,     1,     1,     1,\n",
      "            8,     8,     8,     8,   905,   905,   905,   905,     4,     4,\n",
      "            4,     4,    60,    60,    60,    60,     1,     1,     1,     1,\n",
      "            0,     0,     0,     0], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_next_batch(contexts, window_size, batch_size, epochs_count):\n",
    "    assert batch_size % (window_size * 2) == 0\n",
    "    central_words, contexts = zip(*contexts)\n",
    "    batch_size //= (window_size * 2)\n",
    "    \n",
    "    for epoch in range(epochs_count):\n",
    "        indices = np.arange(len(contexts))\n",
    "        np.random.shuffle(indices)\n",
    "        batch_begin = 0\n",
    "        while batch_begin < len(contexts):\n",
    "            batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
    "            batch_contexts, batch_centrals = [], []\n",
    "            for data_ind in batch_indices:\n",
    "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
    "                batch_contexts.extend(context)\n",
    "                batch_centrals.extend([central_word] * len(context))\n",
    "                \n",
    "            batch_begin += batch_size\n",
    "            yield torch.cuda.LongTensor(batch_contexts), torch.cuda.LongTensor(batch_centrals)\n",
    "\n",
    "print(next(get_next_batch(contexts, window_size=2, batch_size=64, epochs_count=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:30:26.338120Z",
     "start_time": "2020-04-12T22:30:26.327153Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import LongTensor as lt\n",
    "from torch.cuda import FloatTensor as ft\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(voc_size, embedding_dim)\n",
    "    #    self.out_layer = nn.Linear(embedding_dim, voc_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings.forward(inputs)\n",
    "        return projections\n",
    "\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "\n",
    "    def __init__(self, model, voc_size=112084, n_negs=5, weights=None):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self.model = model\n",
    "        self.voc_size = voc_size\n",
    "        self.n_negs = n_negs\n",
    "        self.weights = None\n",
    "        if weights is not None:\n",
    "            wf = np.power(weights, 0.75)\n",
    "            wf = wf / wf.sum()\n",
    "            self.weights = ft(wf)\n",
    "\n",
    "    def forward(self, iword, owords):\n",
    "        batch_size = iword.size()[0]\n",
    "        context_size = 4\n",
    "        nwords = ft(batch_size, context_size * self.n_negs).uniform_(0, self.voc_size - 1).long()\n",
    "        print(nwords.shape)\n",
    "        ivectors = self.model.forward(iword).unsqueeze(2)\n",
    "        ovectors = self.model.forward(owords)\n",
    "        print(ovectors.shape)\n",
    "        nvectors = self.model.forward(nwords).neg()\n",
    "        oloss = torch.bmm(ovectors, ivectors).squeeze().sigmoid().log().mean(1)\n",
    "        nloss = torch.bmm(nvectors, ivectors).squeeze().sigmoid().log().view(-1, context_size, self.n_negs).sum(2).mean(1)\n",
    "        return -(oloss + nloss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:30:27.549977Z",
     "start_time": "2020-04-12T22:30:27.542992Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_negative(contexts, batch_size=256, epochs_count=10, voc_size=112084, embedding_dim =32, n_negs=5, save_path=\"model.pt\",\n",
    "                loss_every_nsteps=1000, lr=0.01, device_name=\"cuda\"):\n",
    "    \n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim \n",
    "    import time\n",
    "    \n",
    "    device = torch.device(device_name)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    model = Word2Vec(voc_size=voc_size, embedding_dim=embedding_dim)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss_function = NegativeSampling(model=model, voc_size=voc_size, n_negs=n_negs, weights=None).cuda() \n",
    "\n",
    "    for step, (batch_contexts, batch_centrals) in enumerate(get_next_batch(contexts, window_size=2, batch_size=batch_size, epochs_count=epochs_count)):\n",
    "        loss = loss_function(batch_centrals, batch_contexts)\n",
    "        print(loss.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if step != 0 and step % loss_every_nsteps == 0:\n",
    "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T22:30:59.059367Z",
     "start_time": "2020-04-12T22:30:59.056399Z"
    }
   },
   "outputs": [],
   "source": [
    "train_negative(contexts[:1000], batch_size = 256, epochs_count=1, voc_size=112084, embedding_dim=32, n_negs=5, save_path=\"negative_sampling.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35hwVrw4sxgs"
   },
   "source": [
    "# Unsupervised targets\n",
    "У пословных моделей есть ряд проблем. Основная - в разных контекстах у одинаковых токенов будут одинаковые представления. Кроме того, наивные Skip-gram и CBoW не учитывают порядок токенов в контексте. \n",
    "\n",
    "Как извлечь информацию из сырых текстов? Чему должны учиться модели, из которых мы получим наши представления?\n",
    "\n",
    "1.   **Skip-gram**\n",
    "2.   **CBoW**\n",
    "3.   LM: language modeling (ELMo, ULMFiT)\n",
    "4.   NSP: next sentence prediction (BERT, в модификациях иногда убирается)\n",
    "5.   MLM: masked language modeling (BERT, основной таргет)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnfBooJYq-Nv"
   },
   "source": [
    "# Языковые модели\n",
    "\n",
    "\n",
    "\n",
    "Языковое моделирование - довольно древняя и понятная задача. Статистичская языковая модель (statistical language model) - вероятностное распределение над последовательностями слов $$P(w_1,...,w_n)$$\n",
    "\n",
    "Другая постановка:\n",
    "$$P(w_n | w_1,...,w_{n-1}) = P(w_n|w_1^{n-1})$$\n",
    "\n",
    "N-граммные модели:\n",
    "\n",
    "$$P(w_n|w_1^{n-1}) \\approx P(w_n|w_{n-N+1}^{n-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsKkyKOZv0s7"
   },
   "source": [
    "## Пример N-граммной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1C3q4SrWLjQ"
   },
   "outputs": [],
   "source": [
    "class NGramModel:\n",
    "    def __init__(self, vocabulary, n=4):\n",
    "        self.n = n\n",
    "        self.n_grams = [Counter() for _ in range(n+1)]\n",
    "        self.vocabulary = vocabulary\n",
    "    \n",
    "    def collect_n_grams(self, tokens):\n",
    "        indices = [vocabulary.get_index(token) for token in tokens]\n",
    "        count = len(indices)\n",
    "        for n in range(self.n + 1):\n",
    "            for i in range(min(count - n + 1, count)):\n",
    "                n_gram = indices[i:i+n]\n",
    "                self.n_grams[n][tuple(n_gram)] += 1\n",
    "                \n",
    "    def normalize(self):\n",
    "        for n in range(self.n, 0, -1):\n",
    "            current_n_grams = self.n_grams[n]\n",
    "            for words, count in current_n_grams.items():\n",
    "                prev_order_n_gram_count = self.n_grams[n-1][words[:-1]]\n",
    "                current_n_grams[words] = count / prev_order_n_gram_count\n",
    "        self.n_grams[0][tuple()] = 1.0\n",
    "    \n",
    "    def predict(self, context):\n",
    "        indices = [vocabulary.get_index(token) for token in context]\n",
    "        context = tuple(indices[-self.n + 1:])\n",
    "        step_probabilities = np.zeros((self.vocabulary.size, ), dtype=np.float64)\n",
    "        for shift in range(self.n):\n",
    "            current_n = self.n - shift\n",
    "            wanted_context_length = current_n - 1\n",
    "            if wanted_context_length > len(context):\n",
    "                continue\n",
    "            start_index = len(context) - wanted_context_length\n",
    "            wanted_context = context[start_index:]\n",
    "            \n",
    "            s = 0.0\n",
    "            for index in range(self.vocabulary.size):\n",
    "                n_gram = wanted_context + (index,)\n",
    "                p = self.n_grams[current_n].get(n_gram, 0)\n",
    "                step_probabilities[index] = p\n",
    "                s += p\n",
    "            if s != 0.0:\n",
    "                break\n",
    "        return step_probabilities\n",
    "\n",
    "vocabulary.word2index[\"<eos>\"] = vocabulary.size\n",
    "vocabulary.index2word.append(\"<eos>\")\n",
    "n_gram_model = NGramModel(vocabulary)\n",
    "for text in texts[:1000]:\n",
    "    n_gram_model.collect_n_grams(text + [\"<eos>\"])\n",
    "n_gram_model.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "HTXLmc1dbOaA",
    "outputId": "893e566d-aa1b-4596-c801-01ce9914ba42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['путин', 'не']\n",
      "['путин', 'не', 'вышел']\n",
      "['путин', 'не', 'вышел', 'к']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим', 'после']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в', 'кемерове']\n",
      "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в', 'кемерове', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "seed = [\"путин\"]\n",
    "while seed[-1] != \"<eos>\":\n",
    "    proba = n_gram_model.predict(seed)\n",
    "    seed.append(np.random.choice(vocabulary.index2word, size=1, p=proba)[0])\n",
    "    print(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvVIpD7mv6Nv"
   },
   "source": [
    "## ELMo (Embeddings from Language Models)\n",
    "\n",
    "Оригинальная статья: https://arxiv.org/pdf/1802.05365.pdf\n",
    "\n",
    "The Illustrated BERT, ELMo and co.: http://jalammar.github.io/illustrated-bert/\n",
    "\n",
    "Как применить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "73HlNt0Lfu12",
    "outputId": "fad6677c-8a91-4669-8f98-59c5db98636a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-28 22:32:41--  http://vectors.nlpl.eu/repository/11/195.zip\n",
      "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
      "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 206977021 (197M) [application/zip]\n",
      "Saving to: ‘195.zip’\n",
      "\n",
      "195.zip             100%[===================>] 197.39M  21.4MB/s    in 13s     \n",
      "\n",
      "2019-10-28 22:32:54 (15.6 MB/s) - ‘195.zip’ saved [206977021/206977021]\n",
      "\n",
      "Archive:  195.zip\n",
      "  inflating: meta.json               \n",
      "  inflating: model.hdf5              \n",
      "  inflating: options.json            \n",
      "  inflating: README                  \n",
      "  inflating: vocab.txt               \n",
      "meta.json  model.hdf5  options.json  README  vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!wget http://vectors.nlpl.eu/repository/11/195.zip\n",
    "!mkdir elmo && mv 195.zip elmo/195.zip && cd elmo && unzip 195.zip && rm 195.zip && cd ..\n",
    "!ls elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T19:28:36.071160Z",
     "start_time": "2020-04-12T19:28:31.788323Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wSLDibTvdC0s"
   },
   "outputs": [],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "path_elmo = 'D:/NLP_advanced/week2/part2/elmo/'\n",
    "elmo = ElmoEmbedder(options_file=path_elmo+\"options.json\", weight_file=path_elmo+\"model.hdf5\", cuda_device=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T19:28:38.756911Z",
     "start_time": "2020-04-12T19:28:36.986936Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "Va79Uo6bgUhb",
    "outputId": "d16209d0-79fa-464f-9b48-cd5da5529f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 38, 1024)\n",
      "(32, 38, 3, 1024)\n",
      "(32, 38, 3072)\n",
      "(32, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0172218 , -0.01318733,  0.04479723, ...,  0.06010765,\n",
       "       -0.18063472,  0.00204151], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings = elmo.batch_to_embeddings(texts[:32])[0].cpu().numpy()\n",
    "print(embeddings.shape)\n",
    "embeddings = embeddings.swapaxes(1, 2)\n",
    "print(embeddings.shape)\n",
    "embeddings = embeddings.reshape(embeddings.shape[0], embeddings.shape[1], -1)\n",
    "print(embeddings.shape)\n",
    "embeddings = np.mean(embeddings, axis=1) \n",
    "print(embeddings.shape)\n",
    "np.mean(embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJ-qbn5Bw4mj"
   },
   "source": [
    "### Задание 4: Рубрикация: ELMo\n",
    "\n",
    "Проверьте, как ELMo работает в задаче рубрикации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T19:28:48.929206Z",
     "start_time": "2020-04-12T19:28:48.922202Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0AU2rEyugzLK"
   },
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "import numpy as np\n",
    "\n",
    "def get_text_embedding_elmo_3072(model, text):\n",
    "    #batch : List[List[str]], required A list of tokenized sentences    \n",
    "    texts = []\n",
    "    # для каждого предложения\n",
    "    for sentence in sentenize(text):\n",
    "        # удаление пунктуации и токенизация\n",
    "        texts.append([token.text.lower() for token in tokenize(sentence.text) if token.text not in punctuation])\n",
    "        \n",
    "    embeddings = model.batch_to_embeddings(texts)[0].cpu().numpy()\n",
    "    embeddings = embeddings.swapaxes(1, 2)\n",
    "    embeddings = embeddings.reshape(embeddings.shape[0], embeddings.shape[1], -1)\n",
    "    embeddings = np.mean(embeddings, axis=1)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def get_text_embedding_elmo_1024(model, text):\n",
    "    #batch : List[List[str]], required A list of tokenized sentences    \n",
    "    texts = []\n",
    "    # для каждого предложения\n",
    "    for sentence in sentenize(text):\n",
    "        # удаление пунктуации и токенизация\n",
    "        texts.append([token.text.lower() for token in tokenize(sentence.text) if token.text not in punctuation])\n",
    "        \n",
    "    embeddings = elmo.batch_to_embeddings(texts[:32])[0].cpu().numpy()\n",
    "    embeddings = embeddings.swapaxes(1, 2)\n",
    "    embeddings = np.mean(embeddings, axis=2) \n",
    "    embeddings = np.mean(embeddings, axis=1) \n",
    "\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T19:29:25.503576Z",
     "start_time": "2020-04-12T19:29:25.499560Z"
    }
   },
   "outputs": [],
   "source": [
    "target_labels = set(train_dataset[\"topic\"].dropna().tolist())\n",
    "target_labels -= {\"69-я параллель\", \"Крым\", \"Культпросвет \", \"Оружие\", \"Бизнес\", \"Путешествия\"}\n",
    "target_labels = list(target_labels)\n",
    "print(target_labels)\n",
    "\n",
    "pattern = r'(\\b{}\\b)'.format('|'.join(target_labels))\n",
    "\n",
    "train_with_topics = train_dataset[train_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "test_with_topics = test_dataset[test_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "emb_size = 1024\n",
    "\n",
    "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_train = np.zeros((train_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(train_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "        print(\"step {}\".format(i))\n",
    "    X_train[i, :] = get_text_embedding_elmo_1024(elmo, phrase)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
    "X_test = np.zeros((test_with_topics.shape[0], emb_size))\n",
    "for i, phrase in enumerate(test_with_topics[\"text\"]):\n",
    "    if i % 5000 == 0:\n",
    "        print(\"step {}\".format(i))\n",
    "    X_test[i, :] = get_text_embedding_elmo_1024(elmo, phrase)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T20:52:29.690233Z",
     "start_time": "2020-04-12T20:52:20.388327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (63356, 1024)\n",
      "X_test shape: (30159, 1024)\n",
      "X_test shape: (63356,)\n",
      "y_test shape: (30159,)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test предрассчитаны в colab\n",
    "import joblib\n",
    "\n",
    "X_train = joblib.load(\"X_train1.pkl\")\n",
    "X_train = X_train.values\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\") \n",
    "X_test = X_test.values\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\") \n",
    "y_train = y_train['0']\n",
    "print(\"X_test shape: {}\".format(y_train.shape))\n",
    "\n",
    "y_test = pd.read_csv(\"y_test.csv\") \n",
    "y_test = y_test['0']\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Многослойный перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T20:39:08.097475Z",
     "start_time": "2020-04-12T20:31:50.752350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      1995\n",
      "           1       0.78      0.77      0.78      2191\n",
      "           2       0.93      0.97      0.95      3429\n",
      "           3       0.78      0.79      0.79      4291\n",
      "           4       0.80      0.73      0.77      2156\n",
      "           5       0.86      0.74      0.80      1177\n",
      "           6       0.71      0.73      0.72      2447\n",
      "           7       0.55      0.74      0.63      1663\n",
      "           8       0.82      0.78      0.80      3185\n",
      "           9       0.81      0.81      0.81      1182\n",
      "          10       0.90      0.76      0.82      2119\n",
      "          11       0.73      0.74      0.73      4324\n",
      "\n",
      "    accuracy                           0.79     30159\n",
      "   macro avg       0.80      0.79      0.79     30159\n",
      "weighted avg       0.80      0.79      0.79     30159\n",
      "\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "# На данных get_text_embedding_elmo_1024\n",
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T20:52:02.040064Z",
     "start_time": "2020-04-12T20:47:37.434361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1995\n",
      "           1       0.80      0.80      0.80      2191\n",
      "           2       0.94      0.97      0.95      3429\n",
      "           3       0.79      0.85      0.82      4291\n",
      "           4       0.83      0.75      0.78      2156\n",
      "           5       0.87      0.72      0.79      1177\n",
      "           6       0.74      0.72      0.73      2447\n",
      "           7       0.57      0.70      0.63      1663\n",
      "           8       0.87      0.76      0.81      3185\n",
      "           9       0.83      0.74      0.78      1182\n",
      "          10       0.90      0.79      0.84      2119\n",
      "          11       0.71      0.79      0.75      4324\n",
      "\n",
      "    accuracy                           0.80     30159\n",
      "   macro avg       0.81      0.79      0.80     30159\n",
      "weighted avg       0.81      0.80      0.80     30159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# На данных get_text_embedding_elmo_1024\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',  solver='saga')\n",
    "clf.fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T20:47:37.433361Z",
     "start_time": "2020-04-12T20:44:10.213976Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      1995\n",
      "           1       0.84      0.78      0.81      2191\n",
      "           2       0.93      0.97      0.95      3429\n",
      "           3       0.79      0.85      0.82      4291\n",
      "           4       0.82      0.76      0.79      2156\n",
      "           5       0.88      0.74      0.80      1177\n",
      "           6       0.75      0.75      0.75      2447\n",
      "           7       0.58      0.72      0.64      1663\n",
      "           8       0.86      0.76      0.81      3185\n",
      "           9       0.84      0.76      0.80      1182\n",
      "          10       0.89      0.79      0.84      2119\n",
      "          11       0.72      0.78      0.75      4324\n",
      "\n",
      "    accuracy                           0.81     30159\n",
      "   macro avg       0.82      0.80      0.80     30159\n",
      "weighted avg       0.81      0.81      0.81     30159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# На данных get_text_embedding_elmo_1024\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jOZyGhYUhHtL",
    "SFpkTIeAjIIU",
    "oSa-1SN-jLLb",
    "qAuVSYDihXKV",
    "No6CwYN9iNxf",
    "-L2oOckSnoC-",
    "JnfBooJYq-Nv"
   ],
   "name": "03_Pytorch_EmbeddingsTraining_LM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
